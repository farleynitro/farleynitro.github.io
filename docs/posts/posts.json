[
  {
    "path": "posts/2022-11-03-capitulo-3-creacin-de-modelos/",
    "title": "Capitulo 3: Creación de modelos",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-11-03",
    "categories": [],
    "contents": "\r\nCargamos los datos y paquetes que necesitamos\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(sjmisc)\r\nlibrary(haven)\r\nlibrary(VIM)\r\nlibrary(kableExtra)\r\nlibrary(skimr)\r\nlibrary(sjPlot)\r\nlibrary(naniar)\r\nlibrary(ggcorrplot)\r\nlibrary(naniar)\r\nlibrary(plyr)\r\nlibrary(dplyr) # df manipulation\r\nlibrary(texreg) # model evaluation\r\nlibrary(MASS) # ordinal regression\r\nlibrary(nnet) # multinomial regression\r\nlibrary(moderndive) # get_regression_table\r\nlibrary(broom)\r\n\r\n\r\nCargamos los datos:\r\n\r\n\r\nrm(list = ls())\r\nind_con_control <- read_sav(\"data/var_independientes_y_control.sav\")\r\ndep_pca_total <- read_sav(\"data/var_dependientes_total_pca.sav\")\r\ndep_pca_importancia <- read_sav(\"data/var_dependientes_importancia_pca.sav\")\r\ndep_pca_preocupacion <- read_sav(\"data/var_dependientes_preocupacion_pca.sav\")\r\ndep_total_clean <- read_sav(\"data/var_dependientes_total_clean_unreduced_final.sav\")\r\n\r\n\r\n1 Construcción de modelo\r\nJuntamos los dataframes:\r\n\r\n\r\nreg_pca_total <- merge(ind_con_control, dep_pca_total,\r\n                          by = 'row.names', all = TRUE)\r\nreg_pca_importancia <- merge(ind_con_control, dep_pca_importancia,\r\n                          by = 'row.names', all = TRUE)\r\nreg_pca_preocupacion <- merge(ind_con_control, dep_pca_preocupacion,\r\n                          by = 'row.names', all = TRUE)\r\ndep_total_clean <- merge(ind_con_control, dep_total_clean,\r\n                          by = 'row.names', all = TRUE)\r\n\r\n\r\nConceptos basicos para modelos de regresion\r\nNuestra variable dependiente es continua ya que se toma el promedio.\r\nRequisitos para regresión múltiple:\r\nTamano muestral elevado de minimo 500 observaciones. Tenemos 6466 observaciones asi que satisfacemos eso.\r\nVariable dependiente tiene que ser continua o dicotómica\r\nMejor es ver relacion individual entre VD y VI y despues anadir al set de componentes\r\nNo anadir variables innecesarias!\r\nPara tener variables significativas , el p < 0.05\r\n1.1 Modelo regresión lineal PCA\r\nVemos que el plot no muestra alguna relación linear. Es algo esperado ya que nuestra variable independiente no es parametrica. Vemos que el indice del PCA esta distribuido por todas partes sin mostral algúna relación con las zonas. Aún asi es posible correr un modelo de regresión lineal múltiple, ya que la regresión sirve como una manera de predecir cuanto incrementa nuestra variable dependiente cuando tienes un incremento de una unidad en nuestra variable(s) independientes. Es decir, la linearidad en regresión asume que es esta relación entre variable dependiente y independiente estan correlacionadas, por la cual es un suposición de nuestro modelo.\r\nCorremos los modelos y controlamos sobre las variables confundidores para ver si aún asi hay alguna significancia estadistica.\r\n\r\n\r\nreg_pca_total %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 01\" ,x = \"Zonas\", y =\"Indice PCA 01\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_total %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indica PCA\" ,x = \"Zonas\", y =\"Indica PCA\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nLas Zonas de Chile no parecen tener ningúna significancia estadistica. Su valor-p > 0.05, indicando que nuestra hipótesis nula es cierta (la percepción no cambia entre zonas). Es mas, el \\(R^{2}\\) ajustado es de 0. No hay ningúna significancia.\r\n\r\n\r\nmodelo_pca_tot_1 <- lm(indice_01 ~ 1 + ZONAS, data = reg_pca_total, na.action = na.exclude)\r\nmodelo_pca_tot_2 <- lm(indice_02 ~ 1 + ZONAS, data = reg_pca_total, na.action = na.exclude)\r\n\r\nmodelos_pca_tot <- list(modelo_pca_tot_1, modelo_pca_tot_2)\r\n\r\nscreenreg(modelos_pca_tot) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    61.60 ***    66.78 ***\r\n               (0.33)       (0.22)   \r\nZONAS           0.04         0.07    \r\n               (0.12)       (0.08)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nControlamos por las variables confundidoras mas relevantes según la literatura. Esto seria, el nivel socio-economico (NSE), el nivel de educación, y la edad.\r\nTampoco las variables confundidoras parecen tener alguna significancia estadistica.\r\n\r\n\r\nmodelo_pca_tot_1_2 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_total, na.action = na.exclude)\r\nmodelo_pca_tot_2_2 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_total, na.action = na.exclude)\r\n\r\nmodelos_pca_tot_2 <- list(modelo_pca_tot_1_2, modelo_pca_tot_2_2)\r\n\r\nscreenreg(modelos_pca_tot_2) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    61.45 ***    66.35 ***\r\n               (1.10)       (0.72)   \r\nZONAS           0.04         0.06    \r\n               (0.12)       (0.08)   \r\nNSE             0.10         0.14    \r\n               (0.17)       (0.11)   \r\nEdad           -0.00        -0.00    \r\n               (0.01)       (0.01)   \r\nNiv_Edu         0.00         0.02    \r\n               (0.09)       (0.06)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nAnadimos todas las variables confundidoras que tenemos. Esto va con el riesgo que hacemos un overfit de nuestro modelo, a nuestros datos especificos. Aún asi, hacemos esto para ver si hay algúna relevancia.\r\nSacamos los nombres de todos las variables independientes:\r\n\r\n\r\ncolnames(ind_con_control)\r\n\r\n [1] \"ZONAS\"                 \"NSE\"                  \r\n [3] \"Edad\"                  \"Niv_Edu\"              \r\n [5] \"Estudiante\"            \"Trab_Ingr\"            \r\n [7] \"Religion\"              \"Razon_Bici\"           \r\n [9] \"Automovil_Combustible\" \"Transporte_mas_freq\"  \r\n\r\nInteresantemente, solo el uso de transporte mas frecuente tiene una significancia estadistica con valor-p <0.05. Continuamos con nuestra investigacion inicial, pero vamos a ver a esta hipótesis, “el uso de transporte afecta tu percepción sobre el cambio climatico”, luego. Lo mantenemos en el fondo de nuestras mentes.\r\n\r\n\r\nmodelo_pca_tot_1_3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_total, na.action = na.exclude)\r\n\r\nmodelo_pca_tot_2_3 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_total, na.action = na.exclude)\r\n\r\nmodelos_pca_tot_3 <- list(modelo_pca_tot_1_3, modelo_pca_tot_2_3)\r\n\r\nscreenreg(modelos_pca_tot_3) \r\n\r\n\r\n===============================================\r\n                       Model 1      Model 2    \r\n-----------------------------------------------\r\n(Intercept)              63.51 ***    68.23 ***\r\n                         (1.91)       (1.24)   \r\nZONAS                     0.01         0.01    \r\n                         (0.16)       (0.10)   \r\nNSE                      -0.27        -0.20    \r\n                         (0.24)       (0.15)   \r\nEdad                     -0.01        -0.00    \r\n                         (0.01)       (0.01)   \r\nEstudiante                0.03        -0.22    \r\n                         (0.56)       (0.36)   \r\nNiv_Edu                  -0.08        -0.00    \r\n                         (0.12)       (0.08)   \r\nRazon_Bici               -0.10        -0.00    \r\n                         (0.07)       (0.05)   \r\nTrab_Ingr                 0.09         0.03    \r\n                         (0.10)       (0.06)   \r\nReligion                  0.04         0.01    \r\n                         (0.10)       (0.06)   \r\nAutomovil_Combustible     0.04        -0.05    \r\n                         (0.28)       (0.18)   \r\nTransporte_mas_freq      -0.04        -0.16 *  \r\n                         (0.12)       (0.07)   \r\n-----------------------------------------------\r\nR^2                       0.00         0.00    \r\nAdj. R^2                 -0.00        -0.00    \r\nNum. obs.              3602         3602       \r\n===============================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nAlmenos vemos que no hay sesgo en la predicción.\r\n\r\n\r\nggplot(mapping = aes(x = modelo_pca_tot_2_3$fitted.values, y = modelo_pca_tot_2_3$residuals)) +\r\n  labs(x = \"Valores predichos\", y = \"Residuos\") +\r\n  geom_point() +\r\n  geom_hline(mapping = aes(yintercept = 0), color = \"red\")\r\n\r\n\r\n\r\nCuando solo el uso de transporte mas frecuente, incluyendo variables confundidoras mas relevantes, vemos que ya no es significante. Mejor no cambiar la hipotesis ya que la significancia depende de controlar (y overfit) el modelo a nuestros datos.\r\n\r\n\r\nmodelo_pca_tot_2_4 <- lm(indice_02 ~ 1 + Transporte_mas_freq, data = reg_pca_total, na.action = na.exclude)\r\nmodelo_pca_tot_2_5 <- lm(indice_02 ~ 1 + Transporte_mas_freq + Edad + NSE + Niv_Edu, data = reg_pca_total, na.action = na.exclude)\r\n\r\n\r\nmodelos_pca_tot_2_4_5 <- list(modelo_pca_tot_2_4, modelo_pca_tot_2_5) \r\nscreenreg(modelos_pca_tot_2_4_5) \r\n\r\n\r\n=============================================\r\n                     Model 1      Model 2    \r\n---------------------------------------------\r\n(Intercept)            67.14 ***    66.67 ***\r\n                       (0.18)       (0.71)   \r\nTransporte_mas_freq    -0.06        -0.06    \r\n                       (0.05)       (0.05)   \r\nEdad                                -0.00    \r\n                                    (0.01)   \r\nNSE                                  0.14    \r\n                                    (0.11)   \r\nNiv_Edu                              0.02    \r\n                                    (0.06)   \r\n---------------------------------------------\r\nR^2                     0.00         0.00    \r\nAdj. R^2                0.00        -0.00    \r\nNum. obs.            6130         6130       \r\n=============================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nModelo regresión lineal PCA total filtrando outliers\r\nVemos que la distribución de los dos indices que creamos en la exploración son un poco diferentes. En el primer indice hay un grupo de datos separados del resto, con un valor entre 0 y 25. En el indice 2 vemos un comportamiento similar, solo que esto grupo es mas pequeno. Podemos ver, si filtramos estos datos si el modelo tendria mas significancia.\r\nLa cantidad de valores bajo el 25 para el indice 1, es de 186, un 3 % de nuestros datos. Para el indice 2 es un 0.05 % de nuestros datos. Asumo que es tan minimo, que filtrar estos subsets no afectaria la predicción del modelo.\r\n\r\n\r\nlength(which(reg_pca_total$indice_01<25))\r\n\r\n[1] 186\r\n\r\nlength(which(reg_pca_total$indice_02<25))\r\n\r\n[1] 3\r\n\r\n\r\n\r\nreg_pca_total_filter_indice1 <- reg_pca_total[reg_pca_total$indice_01  >25, ]\r\nreg_pca_total_filter_indice2 <- reg_pca_total[reg_pca_total$indice_02  >25, ]\r\n\r\n\r\nAún, no parece haber ningúna significancia estadistica.\r\n\r\n\r\nmodelo_pca_tot_1_filtered <- lm(indice_01 ~ 1 + ZONAS, data = reg_pca_total_filter_indice1, na.action = na.exclude)\r\nmodelo_pca_tot_2_filtered <- lm(indice_02 ~ 1 + ZONAS, data = reg_pca_total_filter_indice2, na.action = na.exclude)\r\n\r\nmodelos_pca_tot_filtered <- list(modelo_pca_tot_1_filtered, modelo_pca_tot_2_filtered)\r\n\r\nscreenreg(modelos_pca_tot_filtered) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    63.27 ***    66.80 ***\r\n               (0.19)       (0.22)   \r\nZONAS           0.01         0.07    \r\n               (0.07)       (0.08)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    5944         6127       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nModelo regresión lineal PCA con ordinal smooth\r\nModelo regresión lineal PCA preocupacion\r\nVemos una distribución muy uniforme entres las diferentes zonas. Esto ya indica que no va a hay una relación concreta entre nuestra variable independiente, y dependiente. Sin embargo, si controlamos sobre las variables confundidoras, podriamos tener alguna significancia.\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indica PCA\" ,x = \"Zonas\", y =\"Indica PCA\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indica PCA\" ,x = \"Zonas\", y =\"Indica PCA\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nEl modelo no parece tener algúna relevancia. Nuestra hipótesis, que la zona puede predecir el nivel de preocupación no parece ser valida.\r\n\r\n\r\nmodelo_pca_preo_1 <- lm(indice_01 ~ 1 + ZONAS, data = reg_pca_preocupacion, na.action = na.exclude)\r\nmodelo_pca_preo_2 <- lm(indice_02 ~ 1 + ZONAS, data = reg_pca_preocupacion, na.action = na.exclude)\r\n\r\nmodelos_pca_preo <- list(modelo_pca_preo_1, modelo_pca_preo_2)\r\n\r\nscreenreg(modelos_pca_preo) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    34.84 ***    35.93 ***\r\n               (0.52)       (0.50)   \r\nZONAS           0.17         0.16    \r\n               (0.18)       (0.17)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\n\r\n\r\nmodelo_pca_preo_1_2 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_preocupacion, na.action = na.exclude)\r\nmodelo_pca_preo_2_2 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_preocupacion, na.action = na.exclude)\r\n\r\nmodelos_pca_preo_2 <- list(modelo_pca_preo_1_2, modelo_pca_preo_2_2)\r\n\r\nscreenreg(modelos_pca_preo_2) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    34.57 ***    34.54 ***\r\n               (1.72)       (1.64)   \r\nZONAS           0.16         0.15    \r\n               (0.18)       (0.18)   \r\nNSE             0.34         0.43    \r\n               (0.26)       (0.25)   \r\nEdad           -0.01        -0.00    \r\n               (0.01)       (0.01)   \r\nNiv_Edu        -0.01         0.07    \r\n               (0.14)       (0.13)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2        0.00         0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\n\r\n\r\nmodelo_pca_preo_1_3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_preocupacion, na.action = na.exclude)\r\n\r\nmodelo_pca_preo_2_3 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_preocupacion, na.action = na.exclude)\r\n\r\nmodelos_pca_preo_3 <- list(modelo_pca_preo_1_3, modelo_pca_preo_2_3)\r\n\r\nscreenreg(modelos_pca_preo_3) \r\n\r\n\r\n===============================================\r\n                       Model 1      Model 2    \r\n-----------------------------------------------\r\n(Intercept)              34.37 ***    35.47 ***\r\n                         (2.96)       (2.83)   \r\nZONAS                     0.17         0.06    \r\n                         (0.24)       (0.23)   \r\nNSE                       0.14         0.14    \r\n                         (0.37)       (0.35)   \r\nEdad                     -0.02        -0.00    \r\n                         (0.02)       (0.02)   \r\nEstudiante                0.01        -0.59    \r\n                         (0.86)       (0.83)   \r\nNiv_Edu                   0.07         0.24    \r\n                         (0.19)       (0.18)   \r\nRazon_Bici                0.14         0.15    \r\n                         (0.11)       (0.10)   \r\nTrab_Ingr                 0.13         0.02    \r\n                         (0.15)       (0.14)   \r\nReligion                  0.08        -0.05    \r\n                         (0.15)       (0.14)   \r\nAutomovil_Combustible    -0.33        -0.36    \r\n                         (0.43)       (0.41)   \r\nTransporte_mas_freq      -0.16        -0.22    \r\n                         (0.18)       (0.17)   \r\n-----------------------------------------------\r\nR^2                       0.00         0.00    \r\nAdj. R^2                 -0.00        -0.00    \r\nNum. obs.              3602         3602       \r\n===============================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nModelo regresión lineal PCA importancia\r\n\r\n\r\nreg_pca_importancia %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indica PCA\" ,x = \"Zonas\", y =\"Indica PCA\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_importancia %>% \r\n  ggplot(aes(x = as_factor(ZONAS), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indica PCA\" ,x = \"Zonas\", y =\"Indica PCA\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nEl modelo no parece tener algúna relevancia. Nuestra hipótesis, que la zona puede predecir el nivel de importancia no parece ser valida. El tipo de combustible que alguien tiene un valor-p < 0.05. Sin embargo, para cambiar nuestra hipotesis y cambiar esto hay algunaas cosas que hay que considerar que no todo el mundo tienen un auto. Por esta razon, no se puede filtrar sobre un subgrupo de la populación que tenga vehiculo.\r\n\r\n\r\nmodelo_pca_imp_1 <- lm(indice_01 ~ 1 + ZONAS, data = reg_pca_importancia, na.action = na.exclude)\r\nmodelo_pca_imp_2 <- lm(indice_02 ~ 1 + ZONAS, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelos_pca_imp <- list(modelo_pca_imp_1, modelo_pca_imp_2)\r\n\r\nscreenreg(modelos_pca_imp)\r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    28.77 ***    21.13 ***\r\n               (0.21)       (0.16)   \r\nZONAS          -0.02        -0.00    \r\n               (0.07)       (0.06)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\n\r\n\r\nmodelo_pca_imp_1_2 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_importancia, na.action = na.exclude)\r\nmodelo_pca_imp_2_2 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Niv_Edu, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelos_pca_imp_2 <- list(modelo_pca_imp_1_2, modelo_pca_imp_2_2)\r\n\r\nscreenreg(modelos_pca_imp_2) \r\n\r\n\r\n=====================================\r\n             Model 1      Model 2    \r\n-------------------------------------\r\n(Intercept)    28.27 ***    20.62 ***\r\n               (0.69)       (0.53)   \r\nZONAS          -0.02        -0.00    \r\n               (0.07)       (0.06)   \r\nNSE             0.06         0.07    \r\n               (0.11)       (0.08)   \r\nEdad           -0.00        -0.00    \r\n               (0.01)       (0.00)   \r\nNiv_Edu         0.06         0.06    \r\n               (0.06)       (0.04)   \r\n-------------------------------------\r\nR^2             0.00         0.00    \r\nAdj. R^2       -0.00        -0.00    \r\nNum. obs.    6130         6130       \r\n=====================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\n\r\n\r\nmodelo_pca_imp_1_3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelo_pca_imp_2_3 <- lm(indice_02 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelos_pca_imp_3 <- list(modelo_pca_imp_1_3, modelo_pca_imp_2_3)\r\n\r\nscreenreg(modelos_pca_imp_3) \r\n\r\n\r\n===============================================\r\n                       Model 1      Model 2    \r\n-----------------------------------------------\r\n(Intercept)              29.50 ***    21.43 ***\r\n                         (1.18)       (0.90)   \r\nZONAS                     0.01         0.04    \r\n                         (0.10)       (0.07)   \r\nNSE                       0.06         0.05    \r\n                         (0.15)       (0.11)   \r\nEdad                     -0.01        -0.00    \r\n                         (0.01)       (0.01)   \r\nEstudiante               -0.21        -0.14    \r\n                         (0.34)       (0.26)   \r\nNiv_Edu                  -0.02         0.01    \r\n                         (0.08)       (0.06)   \r\nRazon_Bici                0.05         0.05    \r\n                         (0.04)       (0.03)   \r\nTrab_Ingr                 0.01         0.01    \r\n                         (0.06)       (0.05)   \r\nReligion                  0.05         0.03    \r\n                         (0.06)       (0.04)   \r\nAutomovil_Combustible    -0.40 *      -0.32 *  \r\n                         (0.17)       (0.13)   \r\nTransporte_mas_freq       0.04        -0.00    \r\n                         (0.07)       (0.05)   \r\n-----------------------------------------------\r\nR^2                       0.00         0.00    \r\nAdj. R^2                 -0.00        -0.00    \r\nNum. obs.              3602         3602       \r\n===============================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nCuando solo vemos el uso de combustible, incluyendo variables confundidoras mas relevantes, vemos que ya aun sigue siendo significante esta variable predictiva. Esto los discutimos en la siguiente sección.\r\n\r\n\r\nmodelo_pca_imp_1_4 <- lm(indice_01 ~ 1 + Automovil_Combustible, data = reg_pca_importancia, na.action = na.exclude)\r\nmodelo_pca_imp_1_5 <- lm(indice_01 ~ 1 + Automovil_Combustible + Edad + NSE + Niv_Edu, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelo_pca_imp_2_4 <- lm(indice_02 ~ 1 + Automovil_Combustible, data = reg_pca_importancia, na.action = na.exclude)\r\nmodelo_pca_imp_2_5 <- lm(indice_02 ~ 1 + Automovil_Combustible + Edad + NSE + Niv_Edu, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\n\r\nmodelos_pca_imp_4_5 <- list(modelo_pca_imp_1_4,modelo_pca_imp_1_5,modelo_pca_imp_2_4, modelo_pca_imp_2_5) \r\nscreenreg(modelos_pca_imp_4_5) \r\n\r\n\r\n=========================================================================\r\n                       Model 1      Model 2      Model 3      Model 4    \r\n-------------------------------------------------------------------------\r\n(Intercept)              29.33 ***    29.66 ***    21.60 ***    21.61 ***\r\n                         (0.24)       (0.93)       (0.18)       (0.71)   \r\nAutomovil_Combustible    -0.39 *      -0.38 *      -0.31 *      -0.31 *  \r\n                         (0.17)       (0.17)       (0.13)       (0.13)   \r\nEdad                                  -0.01                     -0.01    \r\n                                      (0.01)                    (0.01)   \r\nNSE                                    0.07                      0.06    \r\n                                      (0.14)                    (0.11)   \r\nNiv_Edu                               -0.00                      0.02    \r\n                                      (0.07)                    (0.06)   \r\n-------------------------------------------------------------------------\r\nR^2                       0.00         0.00         0.00         0.00    \r\nAdj. R^2                  0.00         0.00         0.00         0.00    \r\nNum. obs.              3636         3636         3636         3636       \r\n=========================================================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nSin embargo vemos que hay un sesgo hacia la derecha en los valores predichos.\r\n\r\n\r\n# estimadores <- get_regression_table(modelo_pca_imp_1_5)\r\n# estimadores_obs <- get_regression_points(modelo_pca_imp_1_5)\r\n\r\nggplot(mapping = aes(x = modelo_pca_imp_1_5$fitted.values, y = modelo_pca_imp_1_5$residuals)) +\r\n  labs(x = \"Valores predichos\", y = \"Residuos\") +\r\n  geom_point() +\r\n  geom_hline(mapping = aes(yintercept = 0), color = \"red\")\r\n\r\n\r\n\r\nDiscusión\r\nComo hemos visto los modelos que creamos no parecen tener una significancia estadistica. Esto significa que tampoco es relevante evaluarlas. Durante este proceso hay algúnas observaciones que merecen una discusión. Esta discusión llevara a una solución para tener un modelo útil, sea porque cambiamos la hipótesis, o porque cambiamos nuestra metodologia.\r\nLa manera en la que creamos el indice puede ser incorrecta. Aunque creamos dos diferentes indices, ambas son amiguas.\r\n\r\nEs posible que otras maneras de crear el indice si muestren una significancia.\r\n\r\nAl incluir variables con poca correlacion afectamos la aplicación del PCA.\r\n\r\nEs dificil determinar la correlación entre variables no-parametricas que intentar cuantificar conceptos. Especificamente, en algunos casos incluimos variables que no tienen correlación porque teoreticamente tienen una relación, aunque no se vea en los datos. Podriamos excluir variables con poca correlación, aunque esto signifique que la latente cambie.\r\n\r\nPodriamos cambiar nuestra variable independiente a una que vea la diferencia entre la región metropolitana y el resto de Chile.\r\n\r\nChile tiene una distribución de populación muy concentrada en la región metropolitana (RM) por la que la gente de esta región tiene otros problemas ambientales que el resto de Chile. Para esto podriamos:\r\n\r\n1 crear un PCA nuevo con otras variables dependientes.No lo consideramos por una limitación al tiempo disponible\r\n\r\n2 crear una columna que indice si la zona es afuera o adentro de la región metropolitana. Despues corremos nuevamente los modelos a ver si la predicción mejora. Lo consideramos por una limitación al tiempo disponible\r\n\r\nNuestras latentes podrian no estar bien formuladas porque el concepto sigue siendo muy amplio.\r\n\r\nPara esto podriamos enfocarnos en latentes que conceptualmente sean menos ambiguas. Esto podria enfocarse en una latente que tenga una parilla hecha con un alfa de Cronbach alto. No lo consideramos por una limitación al tiempo disponible\r\n\r\nEl uso de combustible para el vehiculo tiene una significancia estadistica al predecir el indice de importancia. Sin embargo, tengo la idea que hay otra razon por la que muestra significancia. Una variable que domina ambas variables. Esto podria ser la posesion de tener un auto. Requiere mas investigación. No lo consideramos porque cae afuera del marco teórico de esta investigación\r\n\r\nPuede ser que el modelo funcione para modelo no-lineales. Sin embargo, esto requiere tener un muy buen conocimiento de los conceptos para asi entender lo que el modelo predice.No lo consideramos porque cae afuera del contenido de esta clase\r\n\r\nCorremos Analisis Factorial donde determinamos si se pueden clusterizar algúnos conceptos. Esto nos inspira a crear un PCA del conjunto que crea. Si es asi, bien deberiamos de conseguir un modelo con significancia estadistica, y por esto una posible causalidad.\r\n\r\nUsar Analisis Factorial para determinar si se forman dos latentes del P19 y P21. Incluimos las variables que excluimos anteriormente por el alfa de Cronbach.\r\n\r\n\r\n\r\nEnfoque punto 3\r\n\r\n\r\n# #RECODING the values\r\nzonas_rec <- reg_pca_total %>%\r\n  dplyr::select(ZONAS) %>%\r\n  rec(rec= \"1=1;2,3,4=0;else=copy\",suffix=\"\")\r\n\r\nzonas_rec <- reg_pca_importancia %>%\r\n  dplyr::select(ZONAS) %>%\r\n  rec(rec= \"1=1;2,3,4=0;else=copy\",suffix=\"\")\r\n\r\nzonas_rec <- reg_pca_preocupacion %>%\r\n  dplyr::select(ZONAS) %>%\r\n  rec(rec= \"1=1;2,3,4=0;else=copy\",suffix=\"\")\r\n\r\nreg_pca_total$Zonas_recoded <- zonas_rec\r\nreg_pca_importancia$Zonas_recoded <- zonas_rec\r\nreg_pca_preocupacion$Zonas_recoded <- zonas_rec\r\n\r\nreg_pca_total[] <- lapply(reg_pca_total, function(x) as.numeric(as.character(x)))\r\nreg_pca_total <- do.call(data.frame, reg_pca_total)\r\n\r\nreg_pca_importancia[] <- lapply(reg_pca_importancia, function(x) as.numeric(as.character(x)))\r\nreg_pca_importancia <- do.call(data.frame, reg_pca_importancia)\r\n\r\nreg_pca_preocupacion[] <- lapply(reg_pca_preocupacion, function(x) as.numeric(as.character(x)))\r\nreg_pca_preocupacion <- do.call(data.frame, reg_pca_preocupacion)\r\n\r\n\r\n\r\n\r\nreg_pca_importancia %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 1\" ,x = \"Zonas\", y =\"Indice PCA 1\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_importancia %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 2\" ,x = \"Zonas\", y =\"Indice PCA 2\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 1\" ,x = \"Zonas\", y =\"Indica PCA 1\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 2\" ,x = \"Zonas\", y =\"Indice PCA 2\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_01)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 1\" ,x = \"Zonas\", y =\"Indice PCA 1\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\nreg_pca_preocupacion %>% \r\n  ggplot(aes(x = as_factor(Zonas_recoded), y = indice_02)) +\r\n  geom_jitter(shape = 16, position = position_jitter(0.2), color = \"#588157\") +\r\n  geom_point(fill = \"#a3b18a\", color = \"#3a5a40\", alpha = 0.5) +\r\n    labs(title = \"Zonas vs Indice PCA 2\" ,x = \"Zonas\", y =\"Indice PCA 2\") +\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nNada aun. De nuevo el uso de tipo de autocombustible tiene significancia estadistica. Sin embargo, creo que esto es una variable confundidora, ya que hay otra variable que afecta el autocombustible y la percepción.\r\n\r\n\r\nmodelo_pca_preo_enfoque3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_preocupacion, na.action = na.exclude)\r\n\r\nmodelo_pca_imp_enfoque3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_importancia, na.action = na.exclude)\r\n\r\nmodelo_pca_tot_enfoque3 <- lm(indice_01 ~ 1 + ZONAS + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = reg_pca_total, na.action = na.exclude)\r\n\r\n\r\nmodelos_pca_enfoque3 <- list(modelo_pca_preo_enfoque3, modelo_pca_imp_enfoque3, modelo_pca_tot_enfoque3)\r\n\r\nscreenreg(modelos_pca_enfoque3) \r\n\r\n\r\n============================================================\r\n                       Model 1      Model 2      Model 3    \r\n------------------------------------------------------------\r\n(Intercept)              34.37 ***    29.50 ***    63.51 ***\r\n                         (2.96)       (1.18)       (1.91)   \r\nZONAS                     0.17         0.01         0.01    \r\n                         (0.24)       (0.10)       (0.16)   \r\nNSE                       0.14         0.06        -0.27    \r\n                         (0.37)       (0.15)       (0.24)   \r\nEdad                     -0.02        -0.01        -0.01    \r\n                         (0.02)       (0.01)       (0.01)   \r\nEstudiante                0.01        -0.21         0.03    \r\n                         (0.86)       (0.34)       (0.56)   \r\nNiv_Edu                   0.07        -0.02        -0.08    \r\n                         (0.19)       (0.08)       (0.12)   \r\nRazon_Bici                0.14         0.05        -0.10    \r\n                         (0.11)       (0.04)       (0.07)   \r\nTrab_Ingr                 0.13         0.01         0.09    \r\n                         (0.15)       (0.06)       (0.10)   \r\nReligion                  0.08         0.05         0.04    \r\n                         (0.15)       (0.06)       (0.10)   \r\nAutomovil_Combustible    -0.33        -0.40 *       0.04    \r\n                         (0.43)       (0.17)       (0.28)   \r\nTransporte_mas_freq      -0.16         0.04        -0.04    \r\n                         (0.18)       (0.07)       (0.12)   \r\n------------------------------------------------------------\r\nR^2                       0.00         0.00         0.00    \r\nAdj. R^2                 -0.00        -0.00        -0.00    \r\nNum. obs.              3602         3602         3602       \r\n============================================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nEnfoque punto 2\r\nEnfoque punto 4\r\nIntento con P21_promedio\r\nNada…\r\n\r\n\r\nzonas_rec <- dep_total_clean %>%\r\n  dplyr::select(ZONAS.x) %>%\r\n  rec(rec= \"1=1;2,3,4=0;else=copy\",suffix=\"\")\r\n\r\n\r\ndep_total_clean$Zonas_recoded <- zonas_rec\r\n\r\ndep_total_clean[] <- lapply(dep_total_clean, function(x) {\r\n    if(is.factor(x)) as.numeric(as.character(x)) else x\r\n})\r\ndep_total_clean <- do.call(data.frame, dep_total_clean)\r\n\r\n\r\n\r\n\r\nmodelo_P21_promedio_zonas_recoded_enfoque4 <- lm(P21_promedio ~ 1 + Zonas_recoded + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = dep_total_clean, na.action = na.exclude)\r\n\r\nmodelo_P21_promedio_zonas_normal_enfoque4 <- lm(P21_promedio ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici + Trab_Ingr + Religion + Razon_Bici + Automovil_Combustible + Transporte_mas_freq + Religion, data = dep_total_clean, na.action = na.exclude)\r\n\r\nmodelos_P21_promedio_enfoque4 <- list(modelo_P21_promedio_zonas_recoded_enfoque4,modelo_P21_promedio_zonas_normal_enfoque4)\r\n\r\nscreenreg(modelos_P21_promedio_enfoque4)\r\n\r\n\r\n===============================================\r\n                       Model 1      Model 2    \r\n-----------------------------------------------\r\n(Intercept)               4.20 ***     4.19 ***\r\n                         (0.18)       (0.18)   \r\nZonas_recoded             0.02                 \r\n                         (0.04)                \r\nNSE                       0.02         0.02    \r\n                         (0.02)       (0.02)   \r\nEdad                      0.00         0.00    \r\n                         (0.00)       (0.00)   \r\nEstudiante               -0.07        -0.07    \r\n                         (0.05)       (0.05)   \r\nNiv_Edu                   0.01         0.01    \r\n                         (0.01)       (0.01)   \r\nRazon_Bici                0.01         0.01    \r\n                         (0.01)       (0.01)   \r\nTrab_Ingr                 0.01         0.01    \r\n                         (0.01)       (0.01)   \r\nReligion                  0.01         0.01    \r\n                         (0.01)       (0.01)   \r\nAutomovil_Combustible    -0.06 *      -0.06 *  \r\n                         (0.03)       (0.03)   \r\nTransporte_mas_freq       0.00         0.00    \r\n                         (0.01)       (0.01)   \r\nZONAS.x                                0.01    \r\n                                      (0.01)   \r\n-----------------------------------------------\r\nR^2                       0.00         0.00    \r\nAdj. R^2                  0.00         0.00    \r\nNum. obs.              2690         2690       \r\n===============================================\r\n*** p < 0.001; ** p < 0.01; * p < 0.05\r\n\r\nIntento con otro analisis de PCA\r\nParilla 22 Efectividad de acciones (externas/no individuales)\r\nP22A-G ¿Cuán efectivas cree que pueden llegar a hacer las acciones que emprendan para mitigar el cambio climático?: El gobierno y las municipalidades\r\nParilla 19 Sentimientos\r\nParilla 29 Politicas que hay que incorporar\r\nParilla 14 participacion protestas contra cambio climatico\r\nParilla 6 Acciones personales contra cambio climatico\r\n\r\n\r\n\r\n2 Evaluando los mejores modelos\r\nEl AIC mide la “distancia” que existe entre los parámetros verdaderos y los estimadores del modelo mediante una distancia matemática llamada divergencia Kullback-Leibler. Cuanto más pequeña sea la distancia, mejor será el modelo.\r\nEl BIC, a diferencia del AIC, penaliza la complejidad del modelo más rigurosamente ya que además toma en consideración el número de observaciones de la muestra.\r\n\r\n\r\n# broom::glance(modelo.lm)\r\n\r\n\r\nGrafico ROC: Lo más importante de la figura es el área debajo de la curva diagonal que la cruza.\r\nSensibilidad: relación entre los verdaderos positivos y la suma de los verdaderos positivos más los falsos negativos.\r\nEspecificidad: relación entre los verdaderos negativos y la suma de los falsos positivos a los verdaderos negativos.\r\nTener en consideración el cálculo del AUC (Área bajo la Curva): cuanto mayor sea, mejor será el ajuste.\r\nMetodos de evaluación\r\nANOVA is a statistical test for estimating how a quantitative dependent variable changes according to the levels of one or more categorical independent variables. ANOVA tests whether there is a difference in means of the groups at each level of the independent variable.\r\nEsto lo usamos como recurso final para ver si hay variables que no contienen variacion en relación a otras variables independientes. Por ejemplo, si la\r\n[https://www.scribbr.com/statistics/anova-in-r/]\r\n\r\n\r\n# ¿Cuál es el efecto medio?\r\n# \r\n# marginal_ef <- margins(mod1a)\r\n# plot(marginal_ef)\r\n# \r\n# library(pscl)\r\n# \r\n# # Pseudo R-cuadrado\r\n# \r\n# pR2(mod1b)[[\"McFadden\"]]\r\n# \r\n# # Pseudo R cuadrado ajustado\r\n# \r\n# library(DescTools)\r\n# \r\n# PseudoR2(mod1b, c(\"McFadden\"))\r\n\r\n\r\n3 Creación de clusters\r\n\r\n\r\nlibrary(factoextra) # Visualización y cálculos\r\nlibrary(cluster)\r\nlibrary(NbClust) # Cálculo de índices\r\nlibrary(fpc) # Clusters con iteraciones\r\nlibrary(dendextend)\r\nlibrary(tidyverse)\r\n\r\n\r\nVemos para multicolinealidad primero que correr el algoritmo de cluster, porque el K-means es sensitivo a producir clusters incorrectos si se construye a base de dos o mas varianzas similares.\r\nEl clustering es un metodo que agrupa nuestro indice a base de la distancia entre el valor.\r\nVamos a formar clusters a base de las preguntas mas importantes de cada latente que analizamos. Es mejor no considerar demasiadas variables\r\nEstandardizamos las variables. En este caso no estandarizamos las variables porque ya tienen una escala de Likert similar.\r\nCorremos un analisis de multicolinealidad.\r\nAnalizamos usando cluster\r\nEvaluamos los cluster\r\nVamos a ver esto por región ya que hay mas regiones que zonas, haciendo la caracterización por clusters mas significativo. Luego a base de los clusters, y por saber a cual zona pertenece una región, decidimos si en verdad la percepción se puede categorizar a base de las zonas. En su forma, es una forma indirecta de ver si podemos categorizar a base de zona usando la región como variable instrumental.\r\n\r\n\r\ndf_var <- read_sav(\"data/var_dependientes_total.sav\")\r\n\r\n\r\n1\r\nRecordamos las columnas que tenemos:\r\n\r\n\r\ncolnames(df_var)\r\n\r\n [1] \"ZONAS\"        \"REGION\"       \"P34\"          \"P33\"         \r\n [5] \"NSE\"          \"P1_MAmb\"      \"P2_COD\"       \"P3F\"         \r\n [9] \"P4\"           \"P17_COD\"      \"P19_1\"        \"P19_2\"       \r\n[13] \"P19_4\"        \"P19_4.1\"      \"P19_5\"        \"P19_6\"       \r\n[17] \"P19_7\"        \"P19_8\"        \"P19_suma\"     \"P20\"         \r\n[21] \"P21B\"         \"P21C\"         \"P21D\"         \"P21_promedio\"\r\n[25] \"P30\"         \r\n\r\nPara disminuir la influencia que tiene la caracterización a base de variables que no son significativas, formamos varios conceptos de las variables que podrian estar asociadas para la formación de un concepto. Formamos estos clusters a base de una mezcla de analisis cualitativo y cuantitativo. Vemos los conceptos que van juntos con las variables (1), y vemos las dimensiones que conseguimos anteriormente (2). Analizamos 1 y 2 separadamente y vemos si hay alguna consistencia en los resuktados que nos da la clusterización.\r\nIndice de PCA formado\r\nP1_MAmb (importancia relativa), P21D (importancia absoluta)\r\nP19_2 (preocupación), P3F (calidad medio ambiente), P19_1 (Tristeza)\r\nTodo: P1_MAmb, P3F, P19_2, P21D, P19_1\r\nDimension 1 (“Sentimientos de preocupación hacia el cambio climatico”)\r\nDimension 4 (“Percepcion hacia problemas ambientales del medio ambiente de la región”)\r\n\r\n\r\n#clusters\r\nregion_1 <- df_var %>% dplyr::select(REGION,P1_MAmb, P21D)\r\nregion_2 <- df_var %>% dplyr::select(REGION,P19_2, P3F, P19_1)\r\nregion_3 <- df_var %>% dplyr::select(REGION,P19_2, P3F, P19_1,P1_MAmb, P21D)\r\n\r\nzonas_1 <- df_var %>% dplyr::select(ZONAS,P1_MAmb, P21D)\r\nzonas_2 <- df_var %>% dplyr::select(ZONAS,P19_2, P3F, P19_1)\r\nzonas_3 <- df_var %>% dplyr::select(ZONAS,P19_2, P3F, P19_1,P1_MAmb, P21D)\r\n\r\n\r\nedad_3 <- df_var %>% dplyr::select(P33,P19_2, P3F, P19_1,P1_MAmb, P21D)\r\nnse_3 <- df_var %>% dplyr::select(NSE,P19_2, P3F, P19_1,P1_MAmb, P21D)\r\nedu_3 <- df_var %>% dplyr::select(P34,P19_2, P3F, P19_1,P1_MAmb, P21D)\r\n\r\n\r\n2\r\n\r\n\r\nregion_1[c(2, 3)] <- scale(region_1[c(2, 3)])\r\nregion_2[c(2, 3,4)] <- scale(region_2[c(2, 3,4)])\r\nregion_3[c(2, 3,4,5,6)] <- scale(region_3[c(2, 3,4,5,6)])\r\n\r\n\r\n\r\n\r\nedad_3[c(2, 3,4,5,6)] <- scale(edad_3[c(2, 3,4,5,6)])\r\nnse_3[c(2, 3,4,5,6)] <- scale(nse_3[c(2, 3,4,5,6)])\r\nedu_3[c(2, 3,4,5,6)] <- scale(edu_3[c(2, 3,4,5,6)])\r\nzonas_3[c(2, 3,4,5,6)] <- scale(zonas_3[c(2, 3,4,5,6)])\r\n\r\n\r\n3\r\nHay mucho NA (>5%)\r\n\r\n\r\n# library(mice)\r\n# \r\n# md.pattern(region_3)\r\n# \r\n# aggr_plot <- mice:aggr(region_3)\r\n\r\n\r\nRemovemos las columnas con NA ya que no hay manera correcta de imputar sin tener un analisis profundo.\r\n\r\n\r\nregion_3 <- region_3 %>% dplyr::select(REGION, P3F, P1_MAmb)\r\nzonas_3 <- zonas_3 %>% dplyr::select(ZONAS, P3F, P1_MAmb)\r\nedad_3 <- edad_3 %>% dplyr::select(P33, P3F, P1_MAmb)\r\nedu_3 <- edu_3 %>% dplyr::select(P34, P3F, P1_MAmb)\r\nnse_3 <- nse_3 %>% dplyr::select(NSE, P3F, P1_MAmb)\r\n\r\n\r\nNada de que preocuparnos. No hay multicolinealidad.\r\n\r\n\r\nlibrary(GGally)\r\ncor(na.omit(region_3)) #Correlaciones: es necesario omitir los NA. \r\n\r\n             REGION          P3F      P1_MAmb\r\nREGION   1.00000000 -0.026195487  0.013544075\r\nP3F     -0.02619549  1.000000000 -0.002105683\r\nP1_MAmb  0.01354407 -0.002105683  1.000000000\r\n\r\nggcorr(region_3, label = T) #NA se omiten automáticamente\r\n\r\n\r\n\r\n\r\n\r\nlibrary(GGally)\r\ncor(na.omit(zonas_3)) #Correlaciones: es necesario omitir los NA. \r\n\r\n               ZONAS          P3F      P1_MAmb\r\nZONAS    1.000000000 -0.084019245 -0.008959161\r\nP3F     -0.084019245  1.000000000 -0.002105683\r\nP1_MAmb -0.008959161 -0.002105683  1.000000000\r\n\r\nggcorr(zonas_3, label = T) #NA se omiten automáticamente\r\n\r\n\r\n\r\n4\r\nRegión\r\nInteresantemente, para la regiones parece no formar un cluster optimo. El sum of squares inter-clusters es muy bajo, por lo que hay mucho superposición entre los diferentes clusters. Tampoco forma un cluster optimo en cuatro clusters, el número ideal si se podria caracterizar a base de zonas.\r\n\r\n\r\nk1 <- kmeansruns(region_3, krange = 3, runs = 100)\r\n\r\n# Suma de errores al cuadrado entre clusters: la separación entre los clusters explica el 47.5% de los datos\r\nfviz_cluster(k1, data = region_3)\r\n\r\n\r\n\r\n\r\n\r\nd <- dist(region_3, method = \"euclidean\")\r\n\r\n\r\nMétodo de codos\r\n\r\n\r\nfviz_nbclust(region_3, kmeans, method = \"wss\") +\r\n  labs(subtitle = \"Método codos\")\r\n\r\n\r\n\r\nMétodo de brecha estadística\r\nNo lo corremos porque no converge.\r\nMétodo de silueta promedio\r\n\r\n\r\nfviz_nbclust(region_3, kmeans, method = \"silhouette\") +\r\n  labs(subtitle = \"Método de silueta promedio\")\r\n\r\n\r\n\r\nMetodo completo\r\nNo converge.\r\nZonas\r\nHay demasiada diferencia intra-cluster, y muy poca diferencia inter-cluster. Hay aún alguna superposición. Es decir no se puede caracterizar a base de zonas.\r\n\r\n\r\nk2 <- kmeansruns(zonas_3, krange = 4, runs = 100)\r\n# Suma de errores al cuadrado entre clusters: la separación entre los clusters explica el 47.5% de los datos\r\nfviz_cluster(k2, data = zonas_3)\r\n\r\n\r\n\r\nMétodo de codos\r\nIndica k optimo es 10.\r\n\r\n\r\nfviz_nbclust(zonas_3, kmeans, method = \"wss\") +\r\n  labs(subtitle = \"Método codos\")\r\n\r\n\r\n\r\nMétodo de silueta promedio\r\nIndica k optimo es 10.\r\n\r\n\r\nfviz_nbclust(zonas_3, kmeans, method = \"silhouette\") +\r\n  labs(subtitle = \"Método de silueta promedio\")\r\n\r\n\r\n\r\nIMAGINEMOS….\r\nImaginiemos que nada es correcto en nuestra hipótesis y que tenemos que ir a zero. Que no caracterizamos a base de indicadores espaciales. Caracterizamos a base de nuestras variables de control que conceptualmente eran las que eran ciertas. Es decir, caracterizamos a base de la Edad, el Nivel socio-económico, el Nivel de educación. Vamos a ver que tal!\r\nEdad\r\nTampoco se pueden dividir clusters a base de la edad. No hay caracterización que hacer entre personas de diferentes edades.\r\nEntre cluster 1, y 2 si hay alguna diferencia interesante.\r\n\r\n\r\nk3 <- kmeansruns(edad_3, krange = 3, runs = 100)\r\n# Suma de errores al cuadrado entre clusters: la separación entre los clusters explica el 47.5% de los datos\r\nfviz_cluster(k3, data = edad_3)\r\n\r\n\r\n\r\nMétodo de codos\r\nIndica k optimo es 3.\r\n\r\n\r\nfviz_nbclust(edad_3, kmeans, method = \"wss\") +\r\n  labs(subtitle = \"Método codos\")\r\n\r\n\r\n\r\nMétodo de silueta promedio\r\nIndica k optimo es 2.\r\n\r\n\r\nfviz_nbclust(edad_3, kmeans, method = \"silhouette\") +\r\n  labs(subtitle = \"Método de silueta promedio\")\r\n\r\n\r\n\r\nNivel socio-económico\r\nPartimos el k clusters en 5, a pesar del algoritmo, ya que hay solo 5 maneras de caracterizar el NSE. Aún asi vemos que hay mucha superposición entre algúnos clusters.\r\nEntre 1,2,5 si hay una diferencia que se podria investigar.\r\n\r\n\r\nk4 <- kmeansruns(nse_3, krange = 5, runs = 100)\r\n# Suma de errores al cuadrado entre clusters: la separación entre los clusters explica el 47.5% de los datos\r\nfviz_cluster(k4, data = nse_3)\r\n\r\n\r\n\r\nMetodo de codos\r\nIndica k optimo es 10.\r\n\r\n\r\nfviz_nbclust(nse_3, kmeans, method = \"wss\") +\r\n  labs(subtitle = \"Método codos\")\r\n\r\n\r\n\r\nMétodo de silueta promedio\r\nIndica k optimo es 10.\r\n\r\n\r\nfviz_nbclust(nse_3, kmeans, method = \"silhouette\") +\r\n  labs(subtitle = \"Método de silueta promedio\")\r\n\r\n\r\n\r\nNivel de educacion\r\nDemasiada superposición. El sum of squares intra-cluster y inter-cluster tampoco es muy buena. Especialmente inter-cluster no esta muy bueno.\r\n\r\n\r\nk5 <- kmeansruns(edu_3, krange = 10, runs = 100)\r\n# Suma de errores al cuadrado entre clusters: la separación entre los clusters explica el 47.5% de los datos\r\nfviz_cluster(k5, data = edu_3)\r\n\r\n\r\n\r\nMetodo de codos\r\nIndica k optimo es 10.\r\n\r\n\r\nfviz_nbclust(edu_3, kmeans, method = \"wss\") +\r\n  labs(subtitle = \"Método codos\")\r\n\r\n\r\n\r\nMétodo de silueta promedio\r\nIndica k optimo es 2.\r\n\r\n\r\nfviz_nbclust(edu_3, kmeans, method = \"silhouette\") +\r\n  labs(subtitle = \"Método de silueta promedio\")\r\n\r\n\r\n\r\n5\r\nBueno, podemos decir que hay unos clusters de baja calidad, pero de algúna calidad sin embargo para Nivel socio-económico. Parece haber una diferencia significativa entre grupos 1,2,5.\r\nCOMO INVESTIGAMOS ESTO AHORA?\r\n\r\nModelo regresión ordinal/nominal P21D\r\nSegún su percepción, ¿cuán importante es el cambio climático para usted?\r\nModelo regresión logistica ordinal P1_MAmb\r\n\r\n\r\n# modelo_log_p1_control_1 <- as.factor(P1_MAmb) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici\r\n# modelo_log_p1_sin_control <- as.factor(P1_MAmb) ~ 1 + ZONAS.x \r\n# modelo_log_p1_control_2 <- as.factor(P1_MAmb) ~ 1 + ZONAS.x + NSE + Edad\r\n# modelo_log_p1_control_3 <- as.factor(P1_MAmb) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Religion + Razon_Bici + Transporte_mas_freq + Trab_Ingr\r\n# \r\n# \r\n# mod_log_p1_control_1 <- polr(modelo_log_p1_control_1, method= c(\"logistic\"), data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p1_sin_control <- polr(modelo_log_p1_sin_control, method= c(\"logistic\"), data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p1_control_2 <- polr(modelo_log_p1_control_2, method= c(\"logistic\"), data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p1_control_3 <- polr(modelo_log_p1_control_3, method= c(\"logistic\"), data = reg_total_clean, na.action = na.exclude)\r\n# \r\n# modelos_p1 <- list(mod_log_p1_control_1, mod_log_p1_control_2, mod_log_p1_control_3, mod_log_p1_sin_control)\r\n# \r\n# screenreg(modelos_p1)\r\n\r\n\r\nModelo regresión logistica nominal P2\r\n\r\n\r\n# modelo_log_p2_control_1 <- as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici\r\n# modelo_log_p2_sin_control <- as.factor(P2_COD) ~ 1 + ZONAS.x \r\n# modelo_log_p2_control_2 <-  as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad\r\n# modelo_log_p2_control_3 <- as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Religion + Razon_Bici + Transporte_mas_freq + Trab_Ingr\r\n# \r\n# \r\n# mod_log_p2_control_1 <- multinom(modelo_log_p2_control_1, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p2_sin_control <- multinom(modelo_log_p2_sin_control, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p2_control_2 <- multinom(modelo_log_p2_control_2, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p2_control_3 <- multinom(modelo_log_p2_control_3, data = reg_total_clean, na.action = na.exclude)\r\n# \r\n# \r\n# \r\n# \r\n# modelos_p2 <- list(mod_log_p2_control_1, mod_log_p2_control_2, mod_log_p2_control_3, mod_log_p2_sin_control)\r\n# \r\n# screenreg(modelos_p2)\r\n\r\n\r\nModelo regresión logistica nominal P17\r\n\r\n\r\n# modelo_log_p17_control_1 <- as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Razon_Bici\r\n# modelo_log_p17_sin_control <- as.factor(P2_COD) ~ 1 + ZONAS.x \r\n# modelo_log_p17_control_2 <-  as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad\r\n# modelo_log_p17_control_3 <- as.factor(P2_COD) ~ 1 + ZONAS.x + NSE + Edad + Estudiante + Niv_Edu + Religion + Razon_Bici + Transporte_mas_freq + Trab_Ingr\r\n# \r\n# \r\n# mod_log_p17_control_1 <- multinom(modelo_log_p17_control_1, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p17_sin_control <- multinom(modelo_log_p17_sin_control, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p17_control_2 <- multinom(modelo_log_p17_control_2, data = reg_total_clean, na.action = na.exclude)\r\n# mod_log_p17_control_3 <- multinom(modelo_log_p17_control_3, data = reg_total_clean, na.action = na.exclude)\r\n# \r\n# \r\n# \r\n# \r\n# modelos_p17 <- list(mod_log_p17_control_1, mod_log_p17_control_2, mod_log_p17_control_3, mod_log_p17_sin_control)\r\n# \r\n# screenreg(modelos_p17)\r\n\r\n\r\nModelo regresión ordinal/nominal P21 promedio (B, C y D)\r\nPromedioSegún su percepción, ¿cuán importante es el cambio climático para…?: su región (B), familia y amigos (C), usted (D)\r\nModelo regresión lineal multiple P21 PCA (B, C y D)\r\nModelo regresión nominal P2 (Como afecta el medio ambiente)\r\nSegún su percepción, ¿cuál es el principal problema ambiental que lo afecta a Ud.? (codificado)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-03-capitulo-3-creacin-de-modelos/capitulo-3-creacin-de-modelos_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-12-01T17:31:23-03:00",
    "input_file": "capitulo-3-creacin-de-modelos.knit.md"
  },
  {
    "path": "posts/2022-10-19-evaluacin-y-validacin/",
    "title": "Capitulo 4: Evaluación y validación de modelo",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-10-19",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing,\r\nnative to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-03T13:12:25-03:00",
    "input_file": "evaluacin-y-validacin.knit.md"
  },
  {
    "path": "posts/2022-10-05-exploracin-de-datos/",
    "title": "Capitulo 2.1: Exploración de variable independiente y control",
    "description": "Explorando",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-10-05",
    "categories": [],
    "contents": "\r\n1 Limpiando el database\r\nPrimero, cargaremos los paquetes que utilizaremos en esta sesión:\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(sjmisc)\r\nlibrary(haven)\r\nlibrary(kableExtra)\r\nlibrary(readxl)\r\nlibrary(skimr)\r\nlibrary(sjPlot)\r\nlibrary(naniar)\r\nlibrary(ggcorrplot)\r\nlibrary(mice) # Imputación de datos\r\nlibrary(VIM) # Ver los datos perdidos de nuestra base de datos\r\nlibrary(naniar)\r\nlibrary(plyr)\r\nlibrary(dplyr)\r\n\r\n#Cronbach analysis\r\nlibrary(psych)\r\n\r\n\r\nY cargaremos la base de datos con variables ya seleccionadas:\r\n\r\n\r\ndf_2014 <- read_sav(\"data/Base_en_SAV_Primera_Encuesta_Nacional_de_Medio_Ambiente_2014.sav\")\r\ndf_2015 <- read_sav(\"data/Base_en_SAV_Encuesta_Medio_Ambiente_2015.sav\")\r\ndf_2016 <- read_sav(\"data/Base_en_SAV_Encuesta_de_Medio_Ambiente_2016.sav\")\r\ndf_2018 <- read_excel(\"data/Base-en-excel-Encuesta-Nacional-de-Medio-Ambiente-2018.xlsx\")\r\n\r\n\r\nEs importante mencionar que algunas preguntas están doble. Como pregunta abierta, y luego fueron codificadas a base de respuestas similares.\r\n\r\n\r\nskimr::skim(df_2018)\r\n\r\n\r\n\r\n\r\nskimr::skim(df_2016)\r\nsjPlot::view_df(df_2016)\r\n\r\n\r\n\r\n\r\n(sum(is.na(df_2016))/prod(dim(df_2016)))*100\r\n\r\n[1] 2.236765\r\n\r\n\r\n\r\nskimr::skim(df_2015)\r\n\r\n\r\n\r\n\r\n(sum(is.na(df_2015))/prod(dim(df_2015)))*100\r\n\r\n[1] 35.43604\r\n\r\n\r\n\r\nskimr::skim(df_2014)\r\n\r\n\r\n\r\n\r\n(sum(is.na(df_2014))/prod(dim(df_2014)))*100\r\n\r\n[1] 31.38757\r\n\r\nVemos que la cantidad de datos faltantes es poca para el 2016, un 2% de la base.2014 y 2015 ya tienen mas del 30% de datos faltantes. Si ocurre en solo unas de las columnas, se pueden remover de la base para tener una base de datos limpia. Para eso usamos la funcion sort:\r\n\r\n\r\nsort( colSums( sapply(df_2016, is.na) ), decreasing=TRUE) %>% head(20)\r\n\r\n     P50B      P11A      P11B      P11C      P11D      P11E      P11F \r\n     1921      1753      1753      1753      1753      1753      1753 \r\n    P47_A       P48       P49       P50    INICIO   TERMINO     fecha \r\n      716       716       716       716       631       598       163 \r\n     P17F      P17J     FOLIO    COMUNA    region macrozona \r\n        1         1         0         0         0         0 \r\n\r\nVemos que son 14 columnas con datos faltantes para el 2016. De 2170 observaciones, falta más de el 25% (598/2170*100%= 27.2%) de los datos para los indicadores. Removemos todas las columnas que le falten mas de 15% de las observaciones. En vez de observar cuales columnas tiene mas de 15% en el 2015 y 2014, removemos las columnas directamente ya que no son útiles en todo caso.\r\n\r\n\r\ndf_2016_final <- df_2016[, colMeans(is.na(df_2016)) <= .15]\r\ndf_2015_final <- df_2015[, colMeans(is.na(df_2015)) <= .15]\r\ndf_2014_final <- df_2014[, colMeans(is.na(df_2014)) <= .15]\r\n\r\n\r\nEl siguiente Excel ofrece una descripción de la base de datos de las encuestas.\r\nPrimero la data era la siguiente.\r\n\r\n\r\n\r\nAño encuesta\r\n\r\n\r\nObservaciónes\r\n\r\n\r\nPreguntas\r\n\r\n\r\n% Datos faltantes\r\n\r\n\r\nTipos caracter\r\n\r\n\r\nTipos numéricos\r\n\r\n\r\nTipos fecha\r\n\r\n\r\nTipos difftime\r\n\r\n\r\n2014\r\n\r\n\r\n5057\r\n\r\n\r\n89\r\n\r\n\r\n31.90\r\n\r\n\r\n7\r\n\r\n\r\n82\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2015\r\n\r\n\r\n5664\r\n\r\n\r\n113\r\n\r\n\r\n35.40\r\n\r\n\r\n12\r\n\r\n\r\n101\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2016\r\n\r\n\r\n2170\r\n\r\n\r\n344\r\n\r\n\r\n2.23\r\n\r\n\r\n47\r\n\r\n\r\n294\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n2018\r\n\r\n\r\n7601\r\n\r\n\r\n169\r\n\r\n\r\n0.00\r\n\r\n\r\n85\r\n\r\n\r\n84\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n\r\nvemos que habian columnas especificas con la mayoria de los datos faltantes. Las columnas que quedan, juntas, tienen menos del 0.19% con datos faltantes. Esta fracción del total se puede ignorar. Despues de limpiar el database, el overview cambia a la siguiente.\r\n\r\n\r\n(sum(is.na(df_2016_final))/prod(dim(df_2016_final)))*100\r\n\r\n[1] 0.02297186\r\n\r\n(sum(is.na(df_2015_final))/prod(dim(df_2015_final)))*100\r\n\r\n[1] 0.1453809\r\n\r\n(sum(is.na(df_2014_final))/prod(dim(df_2014_final)))*100\r\n\r\n[1] 0.1862764\r\n\r\n\r\n\r\nskimr::skim(df_2014_final)\r\nskimr::skim(df_2015_final)\r\nskimr::skim(df_2016_final)\r\n\r\n\r\n\r\n\r\n\r\nAño encuesta\r\n\r\n\r\nObservaciónes\r\n\r\n\r\nPreguntas\r\n\r\n\r\n% Datos faltantes\r\n\r\n\r\nTipos caracter\r\n\r\n\r\nTipos numéricos\r\n\r\n\r\nTipos fecha\r\n\r\n\r\nTipos difftime\r\n\r\n\r\n2014\r\n\r\n\r\n5057\r\n\r\n\r\n89\r\n\r\n\r\n0.1862764\r\n\r\n\r\n7\r\n\r\n\r\n43\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2015\r\n\r\n\r\n5664\r\n\r\n\r\n113\r\n\r\n\r\n0.1453809\r\n\r\n\r\n12\r\n\r\n\r\n52\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2016\r\n\r\n\r\n2170\r\n\r\n\r\n344\r\n\r\n\r\n0.0229719\r\n\r\n\r\n47\r\n\r\n\r\n283\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n2018\r\n\r\n\r\n7601\r\n\r\n\r\n169\r\n\r\n\r\n0.0000000\r\n\r\n\r\n85\r\n\r\n\r\n84\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n\r\n2 EDA: Encontrando las variables operacionales\r\n2.1 Encuesta nacional del 2018\r\nPara simplificar el analisis, decido enfocarme solo en el 2016 y 2018 ya que es el mas completo de los años. A base del 2016 y 2018 decido cuales van a ser mis variables operacionales para todos los años.\r\n\r\n\r\n#re-ordering dataframe to have indicators in front\r\n\r\ndf_2018_final <- df_2018 %>%\r\n  dplyr::select(\"ZONAS\", \"ID\", \"COMUNA\", \"NSE\",\"TNSE\",\"NEDAD\",\"TEDAD\",\"REGION\",\"CUOTA\",\"POND\", P32,P33,P34,P35,P36,P37,P38,P39, everything())\r\nsjPlot::view_df(df_2018_final)\r\n\r\n\r\n\r\n\r\n\r\n2.2 Exploración de variables independientes\r\nPrimero que escoger mis variables independientes + de control voy a tener que entender su sesgo y varianca. Tengo mas que nada entender mis datos para asi tambien entender mis resultados.\r\nVariables socio-económicos y socio-demograficas son:\r\nZonas (macrozona en Chile)\r\nNSE (nivel Soco-Economico)\r\nTNSE (xxxxx)\r\nNEDAD (categórica de edad; 18-34;31-45; 46-60; 61+)\r\nTEDAD (categórica de edad; 18-34; 35-54; 55+)\r\nP32: Sexo (categórica: Hombre (1); Mujer (0))\r\nP33: Edad (variable continua)\r\nP34: Nivel de educación (categórica del 1-10)\r\nP36: Estudia (categórica: Si(1);No (2))\r\nP37: Nivel de educación con mas aporte al ingreso del hogar (categórica: 1-10)\r\nP38: Profesión con mas aporte al ingreso del hogar (categórica: 1-10)\r\nP39: Religión (categórica: 1-9)\r\nP43: Tipo de combustible que usa el vehiculo del encuestado (categórica: 1-..)\r\nP8: Razón por la que alguien no usa bicicleta (categórica: 1-..)\r\nP18: Opinion de la causa del cambio climatico (categórca: 1-..)\r\nDe estas solo considero las cursivas. Las cursivas voy a analizar para multicolineadid y asi reducir las variables independientes usadas mas.\r\n\r\n\r\n\r\n\r\n\r\n# Rename columns of independent variables\r\ndf_2018_final <-  df_2018_final %>% dplyr::rename('Razon_Bici'= 'P8','Razon_Cambio_Cl'= 'P18','Automovil_Combustible'= 'P43', 'Sexo'='P32' ,'Edad'='P33' ,'Niv_Edu'='P34','Estudiante'='P36','Edu_Ingr'='P37','Trab_Ingr'= 'P38','Religion'='P39', 'Transporte_mas_freq' = 'P7')\r\n\r\n\r\n\r\n\r\nvar_ind <- df_2018_final %>% \r\n  select(ZONAS, NSE, TNSE, NEDAD, TEDAD, Sexo, Edad, Niv_Edu, Estudiante, Edu_Ingr, Trab_Ingr, Religion, Razon_Bici,Razon_Cambio_Cl,Automovil_Combustible, Transporte_mas_freq\r\n         ) %>% \r\n    group_by(ZONAS) %>% \r\nsummarise_all(function(x)  mean(x, na.rm = T))\r\n  # na.omit()\r\n\r\n\r\nVemos que hay un warning. Vamos a ver cual variable ocasiona estos warning y porque. Yo pienso que son Razon_Bici,Razon_Cambio_Cl,Automovil_Combustible. Las ultimas 3 variables tienen un “.”, un dato que se puede considerar NA. Como no se puede reemplezar lo mejor es imputarlo con el valor que es equivalente a “No Responde” para estas preguntas, el número 9 para Razon_Cambio_Cl(P18) y Automovil_Combustible (P43), el número 99 para Razon_Bici (P8). Cambiamos las columnas a numeric y terminamos. Despues, volvemos a formar un subset de las variables independientes.\r\n\r\n\r\nunique(df_2018_final$ZONAS)\r\nunique(df_2018_final$NSE)\r\nunique(df_2018_final$TNSE)\r\nunique(df_2018_final$NEDAD)\r\nunique(df_2018_final$TEDAD)\r\nunique(df_2018_final$Sexo)\r\nunique(df_2018_final$Edad)\r\nunique(df_2018_final$Niv_Edu)\r\nunique(df_2018_final$Estudiante)\r\nunique(df_2018_final$Razon_Bici)\r\nunique(df_2018_final$Razon_Cambio_Cl)\r\nunique(df_2018_final$Automovil_Combustible)\r\nunique(df_2018_final$Transporte_mas_freq)\r\n\r\ndf_2018_final[\"Razon_Bici\"][df_2018_final[\"Razon_Bici\"] == \".\"] <- \"9\"\r\ndf_2018_final[\"Razon_Cambio_Cl\"][df_2018_final[\"Razon_Cambio_Cl\"] == \".\"] <- \"99\"\r\ndf_2018_final[\"Automovil_Combustible\"][df_2018_final[\"Automovil_Combustible\"] == \".\"] <- \"99\"\r\n\r\nvar_ind <- df_2018_final %>% \r\n  select(ZONAS, NSE, TNSE, NEDAD, TEDAD, Sexo, Edad, Niv_Edu, Estudiante, Edu_Ingr, Trab_Ingr, Religion, Razon_Bici,Razon_Cambio_Cl,Automovil_Combustible, Transporte_mas_freq\r\n         ) %>% \r\n    group_by(ZONAS) \r\n\r\n#checking the class of every column\r\nsapply(var_ind, class)\r\n\r\n#applying a new class\r\nvar_ind[] <- lapply(var_ind, function(x) as.numeric(as.character(x)))\r\nsjPlot::view_df(var_ind)\r\n\r\n\r\n2.2.1 Multicolinealidad\r\nEl nivel de correlación para todas las variables es alta ya que las variables son mayormente categóricas. Por eso, solo removemos variables que presenten una correlación alta para la mayoria de variables y que tengan una relación explicativa conceptualmente lógica. Es decir, no consideramos el TNSE,porque el NSE ya captura el estatus socio-económico. TEDAD, NEDAD es reemplazado por la variable continua de edad para tener mejor ajuste y distribución para el input del modelo (la edad es algo que se puede medir).\r\n\r\n\r\n#only include numeric/nominal categoric values\r\n\r\ncolnames(var_ind)\r\n\r\n [1] \"ZONAS\"                 \"NSE\"                  \r\n [3] \"TNSE\"                  \"NEDAD\"                \r\n [5] \"TEDAD\"                 \"Sexo\"                 \r\n [7] \"Edad\"                  \"Niv_Edu\"              \r\n [9] \"Estudiante\"            \"Edu_Ingr\"             \r\n[11] \"Trab_Ingr\"             \"Religion\"             \r\n[13] \"Razon_Bici\"            \"Razon_Cambio_Cl\"      \r\n[15] \"Automovil_Combustible\" \"Transporte_mas_freq\"  \r\n\r\ncorr_vdem <- var_ind %>% \r\n  select(7:16) %>% \r\n  cor(use = \"pairwise\") %>% \r\n  round(1)\r\nggcorrplot(corr_vdem, type = \"lower\", lab = T, tl.cex = 9, show.legend = F)\r\n\r\n\r\nvar_ind <- var_ind %>% \r\n  select(ZONAS, NSE, TNSE, NEDAD, TEDAD, Sexo, Edad, Niv_Edu, Estudiante, Trab_Ingr, Religion, Razon_Bici,Razon_Cambio_Cl,Automovil_Combustible, Transporte_mas_freq\r\n         ) %>% \r\n    group_by(ZONAS)\r\n\r\n\r\nExcluimos la variable Edu_Ingr (¿Cuál es el nivel de educación que alcanzó la persona que aporta el principal ingreso de este hogar?) por su nivel de correlación con Niv_Edu (¿Me podría decir cuál es tu nivel de educación?). Interesantemente, hay una correlación baja entre el Trab_Ing (¿Cuál es la profesión o trabajo de la persona que aporta el principal ingreso de este hogar?) y el Nivel de Educación.\r\nVemos que todas las otras variables tienen colinealidad baja por la que no se presenta multicolinealidad y se pueden usar todas. Importante es saber que muchas de estas variables no son continuas, pero nominales. Ahora vamos a ver las variables ordinales.\r\n\r\n\r\n#only include numeric values\r\n\r\ncolnames(var_ind)\r\n\r\n [1] \"ZONAS\"                 \"NSE\"                  \r\n [3] \"TNSE\"                  \"NEDAD\"                \r\n [5] \"TEDAD\"                 \"Sexo\"                 \r\n [7] \"Edad\"                  \"Niv_Edu\"              \r\n [9] \"Estudiante\"            \"Trab_Ingr\"            \r\n[11] \"Religion\"              \"Razon_Bici\"           \r\n[13] \"Razon_Cambio_Cl\"       \"Automovil_Combustible\"\r\n[15] \"Transporte_mas_freq\"  \r\n\r\ncorr_vdem <- var_ind %>% \r\n  select(1:6) %>% \r\n  cor(use = \"pairwise\") %>% \r\n  round(1)\r\nggcorrplot(corr_vdem, type = \"lower\", lab = T, tl.cex = 9, show.legend = F)\r\n\r\n\r\nvar_ind <- var_ind %>% \r\n  select(ZONAS, NSE, TEDAD, Sexo, Edad, Niv_Edu, Estudiante, Trab_Ingr, Religion, Razon_Bici,Razon_Cambio_Cl,Automovil_Combustible, Transporte_mas_freq\r\n         ) %>% \r\n    group_by(ZONAS)\r\n\r\n\r\nVemos que la NEDAD y TEDAD estan altamente correlacionados. Es logico porque las dos son variables ordinales de la edad. Sin embargo, nos quedamos con TEDAD que divide la edad en cuatro categorias en vez de 3 como por NEDAD. Esto creo que mas varianza en el input del modelo. El TNSE lo excluimos por la misma razon.\r\nPara reducir dimensionalidad y ocuparnos de tener las variables que son significante vamos a reducir la cantidad de variables independientes.\r\nNO ES VALIDO: 2.2.1.1 Chi-Square Test\r\nSi el p<0.05 asumimos que las variables son en verdad independientes. Solo hago el analisis en los que supongo conceptualmente que tienen dependencia.\r\n\r\n\r\nchisq.test(var_ind$Estudiante, var_ind$Trab_Ingr,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Estudiante and var_ind$Trab_Ingr\r\nX-squared = 173.26, df = NA, p-value = 0.01049\r\n\r\nchisq.test(var_ind$Estudiante, var_ind$Razon_Bici,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Estudiante and var_ind$Razon_Bici\r\nX-squared = 245.86, df = NA, p-value = 0.005497\r\n\r\nchisq.test(var_ind$Razon_Bici, var_ind$Razon_Cambio_Cl,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Razon_Bici and var_ind$Razon_Cambio_Cl\r\nX-squared = 146.61, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Razon_Bici, var_ind$Transporte_mas_freq, simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Razon_Bici and var_ind$Transporte_mas_freq\r\nX-squared = 3716.1, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Niv_Edu, var_ind$Estudiante,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Niv_Edu and var_ind$Estudiante\r\nX-squared = 3414.8, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Automovil_Combustible, var_ind$Niv_Edu,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Automovil_Combustible and var_ind$Niv_Edu\r\nX-squared = 849.91, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Niv_Edu, var_ind$NSE,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Niv_Edu and var_ind$NSE\r\nX-squared = 6218.8, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Trab_Ingr, var_ind$NSE,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Trab_Ingr and var_ind$NSE\r\nX-squared = 12215, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$Transporte_mas_freq, var_ind$NSE, simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$Transporte_mas_freq and var_ind$NSE\r\nX-squared = 603.93, df = NA, p-value = 0.0004998\r\n\r\nchisq.test(var_ind$ZONAS, var_ind$NSE,simulate.p.value = TRUE)\r\n\r\n\r\n    Pearson's Chi-squared test with simulated p-value (based on\r\n    2000 replicates)\r\n\r\ndata:  var_ind$ZONAS and var_ind$NSE\r\nX-squared = 52.031, df = NA, p-value = 0.0004998\r\n\r\nTodas parecen ser significantes, y por eso, independientes. Sin embargo, las aproximaciones pueden ser erroneas por los valores tan chicos. Esto resulta en un warning que me dio primero que usar el simulated p-value. Online decia esto:\r\n“It gave the warning because many of the expected values will be very small and therefore the approximations of p may not be right.”\r\n2.2.1.2 TEST-VALIDO: Kruskal Wallis test\r\nPara variables categoricas en realidad no se puede medir la correlacion, porque no son variables parametricas. Por eso, usamos el test Kruskal Wallis, cual mide el Chi-square sobre estas variables ordinales y categoricas. Ya que nuestra variable independiente principal es “ZONA” relacionamos los tests cada vez a esta variable. Si el valor-p es <0.05, asumimos que hay una diferencia significante entre encuestados de diferentes zonas.\r\n\r\n\r\nkruskal.test(ZONAS~ NSE, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by NSE\r\nKruskal-Wallis chi-squared = 33.346, df = 4, p-value =\r\n1.014e-06\r\n\r\nkruskal.test(ZONAS~ TEDAD, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by TEDAD\r\nKruskal-Wallis chi-squared = 49.579, df = 3, p-value =\r\n9.823e-11\r\n\r\nkruskal.test(ZONAS~ Edad, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Edad\r\nKruskal-Wallis chi-squared = 163.69, df = 77, p-value =\r\n3.336e-08\r\n\r\nkruskal.test(ZONAS~ Sexo, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Sexo\r\nKruskal-Wallis chi-squared = 1.8526, df = 1, p-value = 0.1735\r\n\r\nkruskal.test(ZONAS~ Niv_Edu, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Niv_Edu\r\nKruskal-Wallis chi-squared = 39.24, df = 9, p-value =\r\n1.043e-05\r\n\r\nkruskal.test(ZONAS~ Estudiante, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Estudiante\r\nKruskal-Wallis chi-squared = 44.162, df = 3, p-value =\r\n1.394e-09\r\n\r\nkruskal.test(ZONAS~ Trab_Ingr, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Trab_Ingr\r\nKruskal-Wallis chi-squared = 65.623, df = 11, p-value =\r\n8.227e-10\r\n\r\nkruskal.test(ZONAS~ Religion, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Religion\r\nKruskal-Wallis chi-squared = 121.18, df = 7, p-value < 2.2e-16\r\n\r\nkruskal.test(ZONAS~ Razon_Bici, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Razon_Bici\r\nKruskal-Wallis chi-squared = 342.32, df = 11, p-value <\r\n2.2e-16\r\n\r\nkruskal.test(ZONAS~ Razon_Cambio_Cl, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Razon_Cambio_Cl\r\nKruskal-Wallis chi-squared = 64.802, df = 4, p-value =\r\n2.833e-13\r\n\r\nkruskal.test(ZONAS~ Automovil_Combustible, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Automovil_Combustible\r\nKruskal-Wallis chi-squared = 47.257, df = 8, p-value =\r\n1.37e-07\r\n\r\nkruskal.test(ZONAS~ Transporte_mas_freq, data = var_ind)\r\n\r\n\r\n    Kruskal-Wallis rank sum test\r\n\r\ndata:  ZONAS by Transporte_mas_freq\r\nKruskal-Wallis chi-squared = 796.99, df = 8, p-value < 2.2e-16\r\n\r\nVemos que el sexo tiene un valor-p > 0.05 por la que no la consideramos. Tambien vemos que hay mas varianza entre las zonas para la variable ordinal de edad, TEDAD, en vez de la variable parametrica, Edad. Aún asi, tomamos la edad ya que es parametrica.\r\n2.2.1.3 Variables independientes finales\r\nNuestra variable independiente sigue siendo las zonas. Nuestras otras variables sirven como control ya que son indicadores socio-económicos y socio-demograficos.\r\n\r\n\r\nvar_ind_s_control <- var_ind %>% select(ZONAS, NSE, Edad, Niv_Edu, Estudiante, Trab_Ingr, Religion, Razon_Bici, Razon_Cambio_Cl, Automovil_Combustible, Transporte_mas_freq) \r\n\r\n\r\n2.2.2 Visualización\r\nZonas:\r\nVemos que hay mas respondientes en las zona 4 (el Sur), alrededor de un 30% mas. Es importante considerar esto, porque no solo nuestro modelo estara mas entrenado para la zona 4, sino que tambien la relacion nacional (el baseline del analisis) estara sesgado a respondientes de la zona 4. Otras zonas parecen tener una cantidad relativemente igual de encuestados.\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = as_factor(ZONAS))) +\r\n  geom_bar(color = \"#ffafcc\", fill = \"#ffc8dd\", alpha = 0.5) + # Colores\r\n  labs(title = \"Barplot de respondientes por zonas\",\r\n       x = \" \", y = \"Frecuencia\") + # Títulos\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nTEDAD:\r\nVemos que la edad esta razonablemente distruida de una forma normal para cada zona. Sin embargo, vemos que la zona 1 cuenta con una cantidad de encuestados altos bajo la edad de 25. En la zona 4, resalta que una cantidad alta de respondientes esta alrededor de los 50 anos. Las zonas 1 y 2 parecen tener relativamente mas jovenes que las zonas 3 y 4. Sin embargo, casi se puede ignorar esta diferencia.\r\nA nivel nacional, la distribucion es muy similar a los de las zonas con un sesgo ligero a la izquierda, cual se puede deber a las zonas 1 y 2.\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = Edad, na.rm = T)) +\r\n  geom_histogram() +\r\n  facet_grid(~ZONAS) +\r\n  labs(x = \"Edad por Zona\", y = \"Frecuencia\",\r\n       title = \"Edad\",       caption = \"Fuente: Encuesta Nacional 2018\")\r\n\r\n\r\n\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = Edad, na.rm = T)) +\r\n  geom_histogram() +\r\n  labs(x = \"Edad\", y = \"Frecuencia\",\r\n       title = \"Edad distribucion Nacional\", caption = \"Fuente: Encuesta Nacional 2018\")\r\n\r\n\r\n\r\nNSE:\r\nComo se esperaba, el Nivel socioeconomico es mas alto en el Sur. Donde 1 (clase alta, ABC1) y 2 (clase media acomodada, C2) es lo mas alto. 3 a 5 va de clase media a clase mas pobre. El Norte (zona 1) parece tambien tener una cantidad alta de clase alta. La zona central y RM parecen tener una distribucion mas normal con individuos de todas las clases. En todos los clasos, la cantidad de pobres que se entrevisto es muy baja. Esto anade un sesgo al Nivel Socio-económico ya que nos falta datos de la percepción de esta clase de gente. Para la otra clase se puede hablar de una representación relativamente justa.\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = as_factor(NSE))) +\r\n  facet_grid(~ZONAS) +\r\n  geom_bar(color = \"#ffafcc\", fill = \"#ffc8dd\", alpha = 0.5) + # Colores\r\n  labs(title = \"Barplot de NSE dividido en Zonas\",\r\n       x = \" \", y = \"Frecuencia\") + # Títulos\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nNivel de educación:\r\nVemos que en la mayoria de los casos el nivel de educación se divide en dos categorias:\r\n* 1) Universitaria completa (9)\r\n* 2) Media completa (5)\r\nEvidentemente, no hay una distribución normal de los datos. Esto es alarmante ya que indica que la variable puede anadir mucha inprecisión a los resultados del modelo.\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = as_factor(Niv_Edu))) +\r\n  facet_grid(~ZONAS) +\r\n  geom_bar(color = \"#ffafcc\", fill = \"#ffc8dd\", alpha = 0.5) + # Colores\r\n  labs(title = \"Barplot de Nivel de educación por zonas\",\r\n       x = \" \", y = \"Frecuencia\") + # Títulos\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\nOpinion de la razón del cambio climatico:\r\nVemos que la mayoria de los encuestados, sin importar de donde vienen piensan mayormente que el cambio climatico viene por la actividad humana (1). Por esta razón, decidimos excluir esta variable de nuestro set de variables independientes. Una gran cantidad del grupo no respondió (99).\r\n\r\n\r\nvar_ind_s_control %>% \r\n  ggplot(aes(x = as_factor(Razon_Cambio_Cl))) +\r\n  facet_grid(~ZONAS) +\r\n  geom_bar(color = \"#ffafcc\", fill = \"#ffc8dd\", alpha = 0.5) + # Colores\r\n  labs(title = \"Barplot de Razón del cambio climatico por zonas\",\r\n       x = \" \", y = \"Frecuencia\") + # Títulos\r\n  theme_minimal(base_family = \"Roboto Condensed\")\r\n\r\n\r\n\r\n\r\n\r\n#remove all NA from independent variables\r\n\r\nvar_ind[\"Automovil_Combustible\"][var_ind[\"Automovil_Combustible\"] == \"99\"] <- NA\r\nvar_ind[\"Razon_Bici\"][var_ind[\"Razon_Bici\"] == \"99\"] <- NA\r\nvar_ind[\"Razon_Bici\"][var_ind[\"Razon_Bici\"] == \"88\"] <- NA\r\nvar_ind[\"Religion\"][var_ind[\"Religion\"] == \"9\"] <- NA\r\nvar_ind[\"Automovil_Combustible\"][var_ind[\"Automovil_Combustible\"] == \"8\"] <- NA\r\n\r\n\r\n\r\n\r\n#convert all variables to factor\r\n\r\n\r\n\r\n\r\nvar_ind_s_control <- var_ind %>% select(ZONAS, NSE, Edad, Niv_Edu, Estudiante, Trab_Ingr, Religion, Razon_Bici, Automovil_Combustible, Transporte_mas_freq) \r\n\r\n\r\nSalvamos el dataframe para que lo podamos usar en la construcción de los modelos.\r\n\r\n\r\nwrite_sav(var_ind_s_control, \"var_independientes_y_control.sav\")\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-10-05-exploracin-de-datos/exploracin-de-datos_files/figure-html5/unnamed-chunk-21-1.png",
    "last_modified": "2022-11-15T16:01:43-03:00",
    "input_file": "exploracin-de-datos.knit.md"
  },
  {
    "path": "posts/2022-09-14-iteracion-2-formulando-pregunta-de-investigacion/",
    "title": "Capitulo 1.2: Iteración 2: Pregunta de investigacion",
    "description": "Formulando mi pregunta de investigación final. Describo la relación que se modela usando la estadistica.",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-09-14",
    "categories": [],
    "contents": "\r\ní é á\r\nIntroducción\r\nEl cambio climatico a venido a convertirse en un tema importante\r\nglobalmente. La sociedad contemporeana enfrenta un desafio importante\r\nque podria determinar como nuestro futuro se vera, el cambio climatico\r\nantropogenico. El cambio climatico esta definido como el cambio en largo\r\nplazo de temperaturas y los patrones climaticos (UN, 2021). El cambio\r\nclimatico antropogenico es negativo porque puede cambiar nuestro estilo\r\nde vivir. Ya en Chile y Brasil vemos como en los ultimas dos decadas se\r\nexperienció una sequía extrema. Estudios predicen que el cambio\r\nclimático en Latino America no solo afectará los recursos hidrológicos\r\npara consumo de agua, pero tambien afectará el sector agricultural y el\r\nsector hidroeléctrico (Arias et al. 2020;Delgado et al., 2015; IEA,\r\n2020).\r\nEl cambio climatico es mayormente causado por las emisiones de gases\r\n(o emisiones) que retienen el calor solar en nuestro planeta. Estas\r\nemisiones de gases son mayormente consecuencia directa del uso de\r\nrecursos de combustibles fósiles, i.e., recursos esenciales para la\r\neconomia contemporanea.\r\nPara contrarestar este cambio climatico antropogenico,desde 1992 se\r\nhan firmado varias cumbres globales con el proposito de regular (y\r\nreducir) el impacto antropogénico via emisiones al cambio climatico. El\r\nacuerdo mas importante hasta ahorita ha sido el Paris Agreement\r\n(2015) al cual se unieron no mas que ‘193\r\npaises’!\r\nEl viaje a formulacion de politicas para\r\nreducir emisionesTambien en Chile (y Latino America) la situacion de emisiones es\r\ncritica. En Santiago es evidente con la cantidad de smog que hay atrasa\r\nseveramente la salud ambiental y de las personas, posiblemente con\r\nconsecuencias a largo plazo. En la imagen podemos ver que Chile en el\r\n2014 queda en segundo lugar como emitor de gases de invernadero per\r\ncapita. Cuando vemos el tiempo transcurrir entre 2008 y 2018 vemos que\r\nlas emisiones han subido con un 23.8 %. En conclusión, las politicas\r\nparecen no tener efecto para mejorar las emisiones.\r\nLas emisiones CO2 de Chile per capita en\r\ncifras (Banco Mundial,2014)Las emisiones CO2 de Chile total por ano\r\n(Statista, 2018)Formulación 1:\r\nInvestigación inicial\r\nEsto plantea la pregunta de investigación: Ha tenido un efecto\r\npositivo la politica chilena a la polución causada por gases de\r\ninvierno? Para entender su efecto hay que concretar que politicas\r\nambientales han sido implementadas. Esto fue dificil, ya que en varias\r\nocaciones se hablan de metas, pero no de politicas públicas. En la\r\nsiguiente visión general esto se aclara:\r\n2017: Implementacion impuestos verdes de US$5 por tonelada CO2\r\neq.\r\n2018: Plan de Adaptación del Sector Energía\r\n2017-2022: Plan de Acción Nacional de Cambio Climático\r\n2017-2022\r\n2019: El Gobierno se comprometió en 2019 cerrar todas las centrales\r\nde Carbón en Chile al 2040. En 2019 cerraron 4. En 2021 cerraron 4 mas.\r\nEn total hay 28. (Energia, 2021)\r\n2019: Relac en todo Latino America; el 70% de la\r\ngeneración eléctrica en esta parte del mundo sea generada con fuentes de\r\nenergía renovable para el año 2030. Para Chile seria un\r\nmaximo de 95 millones de toneladas de gases de efecto\r\ninvernadero para 2030.\r\nTras analizar el contexto mejor descubrí que el proceso para\r\nconvertir estas politicas en variables operacionales requiere usar de la\r\nmetodologia, Natural Language Processing. La desventaja de este metodo\r\nes que es complicado y requiere un gran montante de datos para que\r\nfuncione correctamente. Al buscar documentos gobernamentales, se\r\ndescubre que se discuten mucho los objetivos de regulaciones sin definir\r\nla regulacion concretamente. Los objetivos son repetidos. Las\r\nregulaciones se definen regionalmente. Politicas que aplican en\r\nla región metropolitana no siempre aplican en otro lugar de\r\nChile. Es decir, minimizar el scope de la investigacion a base\r\nde industria o comuna, requiere mas datos. Mantener el high-level\r\nscope de la investigacion actual, requiere entender cuales\r\ninferencias se pueden hacer. Las dos opciones tienen un alto nivel de\r\ncomplexidad por la falta de datos o la interconexion de inferencias\r\ncausales. Es por esta razón que se ha tenido que iterar en la\r\ninvestigacion.\r\nEs mas, en la ultima decada ya se experenciarion desastres naturales\r\nirregulares. Aunque no sea definido causal, muchos factores apuntan a\r\nque la causa es el cambio climatico para los siguientes\r\nacontecimientos:\r\nEl 2019 es el noveno año consecutivo con temperaturas sobre el\r\npromedio en Chile.\r\nEl 2019 tuvo un déficit promedio de 23% y es el segundo año más seco\r\ndesde 1981.Las localidades con mayores déficits de precipitaciones se\r\nencuentran entre las regiones de Coquimbo hasta Biobío, con un promedio\r\nde -70%.\r\nEn el periodo 2010-2019 se registraron 64 eventos de olas de calor.\r\nEl 2019 hubo un récord de 13 olas de calor en Santiago.\r\nAunque no toda la erosión se produce por el cambio climático, playas\r\ncomo Hornitos (Antofagasta) o Algarrobo (Valparaíso) muestran u\r\nretroceso de más de 2 metros promedio al año.\r\nEn el contexto de las imagenes, entendemos que se puede hablar de una\r\ncrisis medio ambiental en Chile. Una crisis que para cada region es\r\npercibida diferente. En combinación con las cumbres firmadas, supongo\r\nque la percepción sobre la relevancia y los riesgos del cambio climatico\r\ncambia. Los cambios climaticos aumentan las catastrofes experenciadas y\r\npor esto la percepcion de riesgo. Las cumbres aumentan la conciencia\r\nsobre la relevancia del cambio climatico.\r\nFormulación\r\n2: Percepcion pública sobre la importancia del medio ambiente\r\nHipotesis\r\nEn esta investigación queremos concretar los efectos que tiene el\r\ncambio climatico a la percepcion publica. Concretamente se define la\r\nhipotesis como: El aumento de temperatura maxima anual y el\r\naumento de desastres naturales (especificamente, sequia y exceso de\r\nlluvia) afecta negativamente la percepción pública sobre el riesgo del\r\ncambio climático.\r\nVariable independiente: cambios de temperatura máxima y\r\nprecipitación anual.\r\nVariable dependendiente: percepcion publica sobre el riesgo del\r\ncambio climatico.\r\nPrimero que proceder, hay que entender que dice el contexto academico\r\nsobre la relación entre cambios climaticos, cumbres y percepcion\r\npública.\r\nHansen et al. (2012) encuentra que las temperaturas extremas no se\r\npueden explicar por eventos de cambio climatico naturales (ejemplo La\r\nNiña aumentando la sequía y temperatura), indicando una causa\r\nantropogenica.\r\nSchneiderbauer et al. (2021) encuentra que la percepción de riesgo\r\nsobre el cambio climatico es dependiente de experiencas personales,\r\neducación, ingreso y ocupación. Sin embargo, puede ser efecto de\r\nrandomización. Solo un aumento en educación parece estar\r\nrelacionado con un aumento en riesgo sobre cambio climatico.\r\nBagarinao (2016) tambien confirma esto. En otros casos, ocupación y\r\nlocación espacial determina tu vulnerabilidad a peligros naturales. Por\r\nejemplo, un granjero en el desierto de Atacama percibe la sequía como\r\nriesgo, mientras un ciudadano de Santiago percibe la polución como\r\nriesgo del cambio climatico.\r\nSchneiderbauer et al. (2021) tambien encuentra que la percepción de\r\nriesgo es dependiente de factores específicos para un contexto. Es\r\nimportante tener esto en cuenta, ya que puede ser la causa de\r\naleoteridad en los resultados de la investigación.\r\nBagarinao (2016) encuentra que los medios de información entre gente\r\neducada y no-educada afecta el riesgo de percepción. En varios casos se\r\nencuentra una correlacion negativa entre nivel de educacion y\r\nfamiliaridad con planes locales comunitarios contra cambio\r\nclimatico.\r\nUN (2021) conduciendo una encuesta global sobre el medio ambiente,\r\nencuentra que la diferencia en percepción basado en edad se puede\r\nignorar. Tambien se encuentra que las politicas mas populares apoyan la\r\nconservación de naturaleza y aumento en energía renovable. Es decir, ya\r\nse entiende que no se debe investigar una diferencia en percepción para\r\neste tema.\r\nUltimamente Bakaki y Bernauer (2017) encuentran que las\r\nnoticias sobre cumbres globales no afectan la percepción sino la\r\nconciencia sobre el cambio climatico.\r\nEntendiendo esta teoría se puede construír un modelo que cuadre con\r\nel concepto teórico. Esto facilita el proceso de entender los resultados\r\nde la investigación.\r\nFormulación\r\n3: La diferencia entre zonas en percepción pública sobre el cambio\r\nclimatico\r\nA base de la exploración de datos, descrubrimos que la percepción\r\npública es muy amplia para definir, y tambien que la encuesta tiene\r\ndemasiadas preguntas que contestarian un aspecto de esta percepción. Por\r\nesta razón se decidió trabajar con latentes, y asi reducir el ambito de\r\nesta investigación. Luego se cambiara el ambito de nuevo, dependiendo en\r\nla investigacion que logramos formular ahora.\r\nHipotesis: La experiencia personal (a base de la situación\r\nsocio-espacial) con el cambio climático afecta\r\npositivamente/negativamente el riesgo que alguien percibe del cambio\r\nclimático.\r\nSe usan 2 modelos: uno de Chile dividido por zonas,\r\nuno no divido por zonas. La diferencia entre los dos modelos indica si\r\nla percepción cambia relativo al promedio (el promedio es cuando no se\r\ndivide por zonas). Si se nota una diferencia, se puede explicar la\r\ndiferencia de percepción a base de la exposición eventos catastróficos\r\nnaturales (sequia, temperaturas altas, etc.) que tuvieron las personas\r\nde una zona.\r\nVariable independiente: educación, edad, estatus económico, acciones\r\ndiarias (sustentables y no sustentables)\r\nVariable dependiente: una sub-latente (podría ser: preocupación, y\r\nvulnerabilidad) de la percepción del cambio climático.\r\nNos enfocamos en los cuadrantes naranjas para esta investigación.\r\nLa división de la variableVista general de datos\r\nYa que estamos construyendo un data-driven model es\r\nimportante entender que contienen nuestros datos para determinar su\r\nrelevancia para el uso del modelo. Se decidió combinar las percepciones\r\npúblicas a traves de la Encuesta\r\nNacional del Medio Ambiente producido por el Ministerio del Medio\r\nAmbiente, con la base de datos de Registro\r\nHistorico de Estadisticas Ambientales en Chile producido por el\r\nInstituto Nacional de Estadisticas.\r\nEn el siguiente blog se concretará como conducir esta investigación,\r\ncual a su vez determina que modelos y metodos estadísticos seran\r\nusados.\r\nBibliografía\r\nArias, M. E., Farinosi, F., Lee, E., Livino, A., Briscoe, J., &\r\nMoorcroft, P. R. (2020). Impacts of climate change and deforestation on\r\nhydropower planning in the Brazilian Amazon. Nature Sustainability,\r\n3(6), 430-436.\r\nBagarinao, R. T. (2016). Households’ Natural Disaster Preparedness: A\r\nView from a Second Class Municipality in a Developing Country.\r\nEnvironmentAsia, 9(2).\r\nBakaki, Z., & Bernauer, T. (2017). Do global climate summits\r\ninfluence public awareness and policy preferences concerning climate\r\nchange?. Environmental Politics, 26(1), 1-26.\r\nBollettino, V., Alcayna-Stevens, T., Sharma, M., Dy, P., Pham, P.,\r\n& Vinck, P. (2020). Public perception of climate change and disaster\r\npreparedness: Evidence from the Philippines. Climate Risk Management,\r\n30, 100250.\r\nDelgado, L., Torres Gómez, M., Tironi, A., & Marín, V. (2015).\r\nEstrategia de adaptación local al cambio climático para el acceso\r\nequitativo al agua en zonas rurales de Chile.\r\nIEA (2021), Climate Impacts on Latin American Hydropower, IEA, Paris\r\nhttps://www.iea.org/reports/climate-impacts-on-latin-american-hydropower\r\nSchneiderbauer, S., Pisa, P. F., Delves, J. L., Pedoth, L., Rufat,\r\nS., Erschbamer, M., & Granados-Chahin, S. (2021). Risk perception of\r\nclimate change and natural hazards in global mountain regions: A\r\ncritical review. Science of the total environment, 784, 146957.\r\nUN,\r\n2021; What is climate change\r\nCR2,\r\n2014; Emisiones latino america per capita\r\nStatista,\r\n2019; Emisiones de paises Latino Americanos\r\nGobierno\r\nde Chile, 2021; Cierre de Centrales de carbon\r\nWorld’s\r\nlargest survey of public opinion on climate change: a majority of people\r\ncall for wide-ranging action\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-03T13:14:42-03:00",
    "input_file": "iteracion-2-formulando-pregunta-de-investigacion.knit.md"
  },
  {
    "path": "posts/2022-08-25-formulando-la-pregunta-de-investigacin/",
    "title": "Capitulo 1: Formulando la pregunta de investigación",
    "description": "En este post describo mi tema de interes y las variables disponible para este analisis. Esta sera la base de mi investigación para ICP5006.",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-08-25",
    "categories": [],
    "contents": "\r\nIntroducción\r\nLa sociedad contemporeana enfrenta un desafio importante que podria\r\ndeterminar como nuestro futuro se vera, el cambio climatico\r\nantropogenico. El cambio climatico esta definido como el cambio en largo\r\nplazo de temperaturas y los patrones climaticos (UN, 2021). El cambio\r\nclimatico antropogenico es negativo porque puede cambiar el ecosistema a\r\nuno con recursos escarcos, biodiversidad reducida, probalidad\r\nincrementada de hazards naturales, y mas. Todos estas fenomenas haran el\r\nvivir en este planeta como lo conocemos mas dificil. El cambio climatico\r\nantropogenico tendra consecuencias sociales de gran magnitud.\r\nEl cambio climatico es mayormente causado por las emisiones de gases\r\n(o emisiones) que retienen el calor solar en nuestro planeta. Estas\r\nemisiones de gases son mayormente consecuencia directa del uso de\r\nrecursos de combustibles fósiles, i.e., recursos esenciales para la\r\neconomia contemporanea.\r\nPara contrarestar este cambio climatico antropogenico, diferentes\r\ngobiernos alrededor del mundo han firmado varios acuerdos desde 1992\r\npara mitigar el cambio climatico. El acuerdo mas importante hasta\r\nahorita ha sido el Paris Agreement (2015) al cual se\r\nunieron no mas que ‘193 paises’! El proposito es tener\r\nuna meta para la regulacion local de emisiones.\r\nEl viaje a formulacion de politicas para\r\nreducir emisionesTambien en Chile (y Latino America) la situacion de emisiones es\r\ncritica. En Santiago es evidente con la cantidad de smog que hay atrasa\r\nseveramente la salud ambiental y de las personas, posiblemente con\r\nconsecuencias a largo plazo. En la imagen podemos ver que Chile en el\r\n2014 queda en segundo lugar como emitor de gases de invernadero per\r\ncapita.\r\nLas emisiones CO2 de Chile per capita en\r\ncifras (Banco Mundial,2014)Cuando vemos el tiempo transcurrir entre 2008 y 2018 vemos que las\r\nemisiones han subido con un 23.8 %. Esto plantea la pregunta politica:\r\n### Ha tenido efecto la politica chilena a la polucion causada por\r\ngases de invierno?\r\n Para\r\ncualitativamente contestar esta pregunta hay que entender que politicas\r\nambientales el gobierno Chileno ha introducido desde 1990 (fin de la\r\ndemocracia). Estas se pueden sumarizar a base de las metas y politicas\r\npropuestas. Es importante notar que hay una distincion entre la politica\r\ny su efecto. Por esta misma razon, se vuelve interesante evaluar el\r\nefecto agregado de la politica a las emisiones. Asi que, que las\r\nsiguientes politicas han sido introducidas:\r\nFalta informacion de primero que esto….\r\n2017: Implementacion impuestos verdes de US$5 por tonelada CO2\r\neq.\r\n2018: Plan de Adaptación del Sector Energía\r\n2017-2022:Plan de Acción Nacional de Cambio Climático 2017-2022\r\n2019: El Gobierno se comprometió en 2019 cerrar todas las centrales\r\nde Carbón en Chile al 2040. En 2019 cerraron 4. En 2021 cerraron 4 mas.\r\nEn total hay 28. (Energia, 2021)\r\n2019: Relac en todo Latino America; el 70% de la\r\ngeneración eléctrica en esta parte del mundo sea generada con fuentes de\r\nenergía renovable para el año 2030. Para Chile seria un\r\nmaximo de 95 millones de toneladas de gases de efecto\r\ninvernadero para 2030.\r\nTema de enfoque\r\nDependiendo de la base de datos disponibles puedo determinar cual mi\r\nenfoque sera. El enfoque principal es en ‘datos politicos’. En este se\r\ninterpreta: * Politica y polucion: Enfocarse en la dinamica a\r\ntraves del tiempo entre cambios politicos y la polucion en diferentes\r\npartes del ecosistema (agua, aire).\r\nVariables operacionales\r\nEmisiones en CO2 equivalentes\r\n\r\nPorcentage de Urbanizacion\r\n\r\nPorcentage de Agricultura\r\n\r\nConsumo energetico\r\n\r\nGeneracion energetica (no-renovable, o renovable)\r\n\r\nEstatus socio-economico de la poblacion\r\n\r\nAcuerdos internacionales/ Cumbres\r\n\r\nCambio de partido politico\r\n\r\nGobernancia de legislicacion\r\n\r\nCambios electorales\r\n\r\nInclinacion democratica del gobierno\r\n\r\nPara esto he encontrado varios bases de datos:\r\nRegistro de\r\nEmisiones y Transferencias de Contaminantes (RETC)\r\nWorld Bank Data\r\npara Chile\r\nOCHA\r\nUN de Chile para indicadores ecologicos\r\nEmisiones\r\nde Chile segun el Banco Mundial Chile\r\nHipotesis\r\nMi hipotesis es la siguiente: Las emisiones tienen\r\nuna relacion debil con el cambio de politica\r\nSubhipotesis: a) Dependiendo de la industria el efecto de la\r\npolitica es mas fuerte o menos fuerte.\r\nArgumentos:\r\nViendo que las emisiones siguien subiendo en Chile, es la pregunta si\r\nestas politicas han tenido efecto.\r\nReferencias\r\nUN,\r\n2021; What is climate change\r\nCR2,\r\n2014; Emisiones latino america per capita\r\nStatista,\r\n2019; Emisiones de paises Latino Americanos\r\nGobierno\r\nde Chile, 2021; Cierre de Centrales de carbon\r\nDistill is a publication format for scientific and technical writing,\r\nnative to the web.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-03T13:14:20-03:00",
    "input_file": "formulando-la-pregunta-de-investigacin.knit.md"
  },
  {
    "path": "posts/2022-08-19-week-1/",
    "title": "Capitulo 0: Experiencia nueva con R",
    "description": "Experiencia de la primera semana",
    "author": [
      {
        "name": "Farley Rimon",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-08-19",
    "categories": [],
    "contents": "\r\nSo far, struggling a little\r\nbit\r\nThings tend to go slow for several reasons:\r\n\r\nI just want to get started with the projects!\r\n\r\nProgram interface (to zoom or not to zoom?)\r\nDisbalance in student expertise\r\nI just want to get started with the projects!Or the hardcore\r\n(new) theory. I believe reviewing old material is to be done in\r\nsomeone’s own time. Well, that’s how my uni went so I am used to the\r\nstress hahaha. It is also just part of my natural character. Because of\r\nthis, I am excited for what is to come…\r\nFinished taller de R\r\nExperience: + Not very different to Python + Need to get used to the\r\nsyntax + Actually pretty easy to use. The interface is insanely simple +\r\nI am scared some solutions I will not know because of a lack of\r\ndominance of R. Hopefully we can help each other with\r\nthis.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-03T13:12:18-03:00",
    "input_file": "week-1.knit.md"
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to ICP5006 Blog of Farley Rimon",
    "description": "Welcome to our new blog, ICP5006 Blog of Farley Rimon. Here you can keep track of the progress made during the course. I will document my     opinion on findings about projects related to urban data analysis.",
    "author": [
      {
        "name": "Farley Rimon",
        "url": {}
      }
    ],
    "date": "2022-08-19",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-08-23T09:34:07-04:00",
    "input_file": {}
  }
]
